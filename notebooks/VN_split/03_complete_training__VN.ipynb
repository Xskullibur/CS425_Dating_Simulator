{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete VN Training Pipeline - Visual Novel Dating Simulator ðŸ¤–â¤ï¸\n",
    "\n",
    "**Purpose:** Self-contained notebook for training LLaMA 3.1 on VN (Doki Doki Literature Club) dating simulator\n",
    "\n",
    "**What this notebook does:**\n",
    "1. ðŸ“š Loads pre-formatted VN JSONL data (all 4 characters: Monika, Sayori, Natsuki, Yuri)\n",
    "2. ðŸ“ Uses pre-formatted messages with affection tracking and emotion guidance\n",
    "3. ðŸŽ¯ Fine-tunes LLaMA 3.1 with LoRA on multi-turn conversations\n",
    "4. âœ… Tests generation with FIXED parameters (no repetition, proper stopping)\n",
    "\n",
    "**Key Features:**\n",
    "- Combines all 4 VN characters (439 total examples)\n",
    "- Pre-formatted messages (no manual formatting needed)\n",
    "- Affection tracking included in system prompts (0-100 scale)\n",
    "- Emotion-based guidance for appropriate responses\n",
    "- Multi-turn conversation support\n",
    "- Fixed generation function (proper EOS token, repetition penalty)\n",
    "- Immediate testing after training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from jinja2->torch) (3.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pandas in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: numpy in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (2.3.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tqdm in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (4.67.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: seaborn in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from seaborn) (2.3.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: transformers in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (4.57.1)\n",
      "Requirement already satisfied: filelock in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers) (2025.10.23)\n",
      "Requirement already satisfied: requests in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->transformers) (2025.10.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: datasets in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (4.3.0)\n",
      "Requirement already satisfied: filelock in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (2.3.4)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: anyio in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.1.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: accelerate in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from accelerate) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from accelerate) (7.1.1)\n",
      "Requirement already satisfied: pyyaml in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from accelerate) (2.9.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: filelock in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.9.0)\n",
      "Requirement already satisfied: requests in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.10)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.10.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: bitsandbytes in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (0.48.1)\n",
      "Requirement already satisfied: torch<3,>=2.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from bitsandbytes) (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from bitsandbytes) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.9 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from bitsandbytes) (25.0)\n",
      "Requirement already satisfied: filelock in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\n",
      "Requirement already satisfied: jinja2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tensorboard in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from tensorboard) (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from tensorboard) (1.76.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from tensorboard) (3.9)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from tensorboard) (2.3.4)\n",
      "Requirement already satisfied: packaging in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from tensorboard) (25.0)\n",
      "Requirement already satisfied: pillow in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from tensorboard) (12.0.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from tensorboard) (6.33.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from tensorboard) (80.9.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: typing-extensions~=4.12 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from grpcio>=1.48.2->tensorboard) (4.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pyyaml in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (6.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: peft in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (0.17.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from peft) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from peft) (25.0)\n",
      "Requirement already satisfied: psutil in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from peft) (7.1.1)\n",
      "Requirement already satisfied: pyyaml in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from peft) (6.0.3)\n",
      "Requirement already satisfied: torch>=1.13.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from peft) (2.9.0)\n",
      "Requirement already satisfied: transformers in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from peft) (4.57.1)\n",
      "Requirement already satisfied: tqdm in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from peft) (1.11.0)\n",
      "Requirement already satisfied: safetensors in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from peft) (0.6.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from peft) (0.36.0)\n",
      "Requirement already satisfied: filelock in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (2025.9.0)\n",
      "Requirement already satisfied: requests in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (2.32.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (1.1.10)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.5)\n",
      "Requirement already satisfied: jinja2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.10.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers->peft) (2025.10.23)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers->peft) (0.22.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: ipywidgets in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (8.1.8)\n",
      "Requirement already satisfied: traitlets in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (5.14.3)\n",
      "Requirement already satisfied: ipykernel in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (7.1.0)\n",
      "Requirement already satisfied: tqdm in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipywidgets) (9.6.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipykernel) (1.8.17)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipykernel) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipykernel) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging>=22 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipykernel) (25.0)\n",
      "Requirement already satisfied: psutil>=5.7 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipykernel) (7.1.1)\n",
      "Requirement already satisfied: pyzmq>=25 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipykernel) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipykernel) (6.5.2)\n",
      "Requirement already satisfied: decorator in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.15.0)\n",
      "Requirement already satisfied: wcwidth in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from jupyter-client>=8.0.0->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.5.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch\n",
    "!pip3 install pandas\n",
    "!pip3 install numpy\n",
    "!pip3 install tqdm\n",
    "!pip3 install matplotlib\n",
    "!pip3 install seaborn\n",
    "!pip3 install transformers\n",
    "!pip3 install datasets\n",
    "!pip3 install accelerate\n",
    "!pip3 install bitsandbytes\n",
    "!pip3 install tensorboard\n",
    "!pip3 install pyyaml\n",
    "!pip3 install peft\n",
    "!pip3 install --upgrade ipywidgets traitlets ipykernel tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  Current directory: /common/home/projectgrps/CS425/CS425G3/CS425-Dating-Simulator/notebooks/VN_split\n",
      "Please run from notebooks/VN/ directory\n"
     ]
    }
   ],
   "source": [
    "# Check environment\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent to path\n",
    "if Path.cwd().name == 'VN':\n",
    "    sys.path.insert(0, str(Path.cwd().parent.parent))\n",
    "    print(\"âœ“ Running from VN directory\")\n",
    "else:\n",
    "    print(f\"âš ï¸  Current directory: {Path.cwd()}\")\n",
    "    print(\"Please run from notebooks/VN/ directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Transformers and PEFT\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    "    TaskType\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ“ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA A40\n",
      "Memory: 47.71 GB\n",
      "CUDA Version: 12.8\n"
     ]
    }
   ],
   "source": [
    "# GPU Configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    \n",
    "    # Clear cache\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"âš ï¸  No GPU detected - training will be VERY slow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training Configuration\n",
    "\n",
    "**âš ï¸ CUSTOMIZE THESE SETTINGS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Model: meta-llama/Llama-3.1-8B-Instruct\n",
      "  VN Data Dir: ../../data/processed/VN/processed/\n",
      "  Characters: Monika, Sayori, Natsuki, Yuri\n",
      "  Output: ../../checkpoints/dating_sim_vn\n",
      "  Epochs: 12\n",
      "  Effective batch size: 8\n"
     ]
    }
   ],
   "source": [
    "# ==================== CONFIGURATION ====================\n",
    "\n",
    "# Model settings\n",
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# Data paths - Load all 4 VN character JSONL files\n",
    "VN_DATA_DIR = \"../../data/processed/VN/processed/\"\n",
    "VN_CHARACTERS = ['Monika', 'Sayori', 'Natsuki', 'Yuri']\n",
    "OUTPUT_DIR = \"../../checkpoints/dating_sim_vn\"\n",
    "\n",
    "# Training hyperparameters\n",
    "CONFIG = {\n",
    "    # Data\n",
    "    'max_length': 128,\n",
    "    'train_split': 0.9,\n",
    "    \n",
    "    # Training\n",
    "    'num_epochs': 12,\n",
    "    'batch_size': 2,\n",
    "    'gradient_accumulation_steps': 4,\n",
    "    'learning_rate': 2e-4,\n",
    "    'warmup_steps': 100,\n",
    "    'weight_decay': 0.01,\n",
    "    \n",
    "    # LoRA parameters\n",
    "    'lora_r': 8,\n",
    "    'lora_alpha': 16,\n",
    "    'lora_dropout': 0.05,\n",
    "    'lora_target_modules': ['q_proj', 'v_proj', 'k_proj', 'o_proj'],\n",
    "    \n",
    "    # Memory optimization\n",
    "    'gradient_checkpointing': True,\n",
    "    'fp16': True,\n",
    "    'bf16': False,\n",
    "    \n",
    "    # Logging\n",
    "    'logging_steps': 10,\n",
    "    'eval_steps': 30,\n",
    "    'save_steps': 30,\n",
    "    'save_total_limit': 3,\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Model: {MODEL_NAME}\")\n",
    "print(f\"  VN Data Dir: {VN_DATA_DIR}\")\n",
    "print(f\"  Characters: {', '.join(VN_CHARACTERS)}\")\n",
    "print(f\"  Output: {OUTPUT_DIR}\")\n",
    "print(f\"  Epochs: {CONFIG['num_epochs']}\")\n",
    "print(f\"  Effective batch size: {CONFIG['batch_size'] * CONFIG['gradient_accumulation_steps']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Load Raw Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading VN data from all characters...\n",
      "  Loading Monika... âœ“ 29 examples\n",
      "  Loading Sayori... âœ“ 49 examples\n",
      "  Loading Natsuki... âœ“ 52 examples\n",
      "  Loading Yuri... âœ“ 70 examples\n",
      "\n",
      "âœ“ Total loaded: 200 training examples\n",
      "\n",
      "Columns: ['messages']\n",
      "Dataset shape: (200, 1)\n",
      "\n",
      "Sample data (first example's messages):\n",
      "  system: You are Monika, the Literature Club president. Confident, intelligent, and caring. You're thoughtful...\n",
      "  user: Don't make promises you can't keep! Fine... I'll stop by for a cupcake, okay? I told you, don't call...\n",
      "  ... (6 total messages in this example)\n"
     ]
    }
   ],
   "source": [
    "# Load VN JSONL data from all 4 characters\n",
    "print(\"Loading VN data from all characters...\")\n",
    "all_data = []\n",
    "\n",
    "for character in VN_CHARACTERS:\n",
    "    file_path = f\"{VN_DATA_DIR}/vn_training_data_{character}_cleaned.jsonl\"\n",
    "    print(f\"  Loading {character}...\", end=\" \")\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        char_data = [json.loads(line) for line in f]\n",
    "        all_data.extend(char_data)\n",
    "        print(f\"âœ“ {len(char_data)} examples\")\n",
    "\n",
    "print(f\"\\nâœ“ Total loaded: {len(all_data)} training examples\")\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample data (first example's messages):\")\n",
    "if len(df) > 0:\n",
    "    sample_messages = df.iloc[0]['messages']\n",
    "    for msg in sample_messages[:2]:  # Show first 2 messages\n",
    "        print(f\"  {msg['role']}: {msg['content'][:100]}...\")\n",
    "    print(f\"  ... ({len(sample_messages)} total messages in this example)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Character Distribution\n",
      "================================================================================\n",
      "Yuri           :    70 (35.00%)\n",
      "Natsuki        :    52 (26.00%)\n",
      "Sayori         :    49 (24.50%)\n",
      "Monika         :    29 (14.50%)\n",
      "\n",
      "================================================================================\n",
      "Affection Distribution\n",
      "================================================================================\n",
      "Mean           : 50.1/100\n",
      "Median (50%)   : 52.0/100\n",
      "Min            : 0/100\n",
      "Max            : 92/100\n",
      "\n",
      "================================================================================\n",
      "Multi-turn Conversation Statistics\n",
      "================================================================================\n",
      "Mean turns     : 8.3\n",
      "Median turns   : 8.0\n",
      "Min turns      : 3\n",
      "Max turns      : 16\n"
     ]
    }
   ],
   "source": [
    "# Data statistics\n",
    "print(\"=\"*80)\n",
    "print(\"Character Distribution\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Extract character from system prompt\n",
    "def extract_character(messages):\n",
    "    \"\"\"Extract character name from system prompt\"\"\"\n",
    "    system_msg = messages[0]['content'] if messages and messages[0]['role'] == 'system' else \"\"\n",
    "    for char in VN_CHARACTERS:\n",
    "        if f\"You are {char}\" in system_msg:\n",
    "            return char\n",
    "    return \"Unknown\"\n",
    "\n",
    "df['character'] = df['messages'].apply(extract_character)\n",
    "char_counts = df['character'].value_counts()\n",
    "\n",
    "for char, count in char_counts.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"{char:15s}: {count:5d} ({percentage:5.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Affection Distribution\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Extract affection from system prompt\n",
    "def extract_affection(messages):\n",
    "    \"\"\"Extract affection level from system prompt\"\"\"\n",
    "    system_msg = messages[0]['content'] if messages and messages[0]['role'] == 'system' else \"\"\n",
    "    import re\n",
    "    match = re.search(r'Current affection: (\\d+)/100', system_msg)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "df['affection'] = df['messages'].apply(extract_affection)\n",
    "affection_stats = df['affection'].describe()\n",
    "\n",
    "print(f\"{'Mean':<15s}: {affection_stats['mean']:.1f}/100\")\n",
    "print(f\"{'Median (50%)':<15s}: {affection_stats['50%']:.1f}/100\")\n",
    "print(f\"{'Min':<15s}: {affection_stats['min']:.0f}/100\")\n",
    "print(f\"{'Max':<15s}: {affection_stats['max']:.0f}/100\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Multi-turn Conversation Statistics\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Count turns per conversation\n",
    "df['num_turns'] = df['messages'].apply(len)\n",
    "turn_stats = df['num_turns'].describe()\n",
    "\n",
    "print(f\"{'Mean turns':<15s}: {turn_stats['mean']:.1f}\")\n",
    "print(f\"{'Median turns':<15s}: {turn_stats['50%']:.1f}\")\n",
    "print(f\"{'Min turns':<15s}: {turn_stats['min']:.0f}\")\n",
    "print(f\"{'Max turns':<15s}: {turn_stats['max']:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Load Tokenizer for Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LLaMA 3.1 tokenizer for data formatting...\n",
      "âœ“ Tokenizer loaded: PreTrainedTokenizerFast\n",
      "  Special tokens: {'bos_token': '<|begin_of_text|>', 'eos_token': '<|eot_id|>'}\n",
      "  EOS token: <|eot_id|> (ID: 128009)\n"
     ]
    }
   ],
   "source": [
    "# Load LLaMA 3.1 tokenizer\n",
    "print(\"Loading LLaMA 3.1 tokenizer for data formatting...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "print(f\"âœ“ Tokenizer loaded: {tokenizer.__class__.__name__}\")\n",
    "print(f\"  Special tokens: {tokenizer.special_tokens_map}\")\n",
    "print(f\"  EOS token: {tokenizer.eos_token} (ID: {tokenizer.eos_token_id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Format Data with LLaMA 3.1 Instruction Template\n",
    "\n",
    "**Note:** VN data is already pre-formatted with character personas, affection tracking, and emotion guidance in the system prompts. We just need to apply the chat template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Apply Chat Template to Pre-formatted Messages\n",
    "\n",
    "VN data already contains complete conversations with system/user/assistant messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Formatting function defined\n",
      "\n",
      "This function simply applies the LLaMA 3.1 chat template to\n",
      "pre-formatted VN conversations (no persona building or scenario generation needed)\n"
     ]
    }
   ],
   "source": [
    "def format_vn_conversation(messages):\n",
    "    \"\"\"\n",
    "    Apply LLaMA 3.1 chat template to pre-formatted VN messages.\n",
    "    \n",
    "    VN data already has:\n",
    "    - System prompt with character description\n",
    "    - Affection tracking (e.g., \"Current affection: 25/100\")\n",
    "    - Emotion guidance (e.g., \"The user is happy! Match their enthusiasm\")\n",
    "    - Multi-turn user/assistant dialogue\n",
    "    \n",
    "    We just apply the chat template to format for LLaMA 3.1.\n",
    "    \"\"\"\n",
    "    # Apply LLaMA 3.1 chat template\n",
    "    formatted = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False  # Don't add generation prompt for training\n",
    "    )\n",
    "    \n",
    "    return formatted\n",
    "\n",
    "print(\"âœ“ Formatting function defined\")\n",
    "print(\"\\nThis function simply applies the LLaMA 3.1 chat template to\")\n",
    "print(\"pre-formatted VN conversations (no persona building or scenario generation needed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Sample Formatted Conversation (LLaMA 3.1 Format)\n",
      "================================================================================\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are Monika, the Literature Club president. Confident, intelligent, and caring. You're thoughtful and philosophical, ambitious and kind with a mysterious side. Current affection: 8/100 User's emotional state: neutral Respond naturally based on the conversation context.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Don't make promises you can't keep! Fine... I'll stop by for a cupcake, okay? I told you, don't call me a 'new member--'<|eot_id|><|start_header_id|>ass...\n",
      "\n",
      "================================================================================\n",
      "Full length: 978 characters\n"
     ]
    }
   ],
   "source": [
    "# Test formatting with a sample\n",
    "print(\"=\"*80)\n",
    "print(\"Sample Formatted Conversation (LLaMA 3.1 Format)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sample_messages = df.iloc[0]['messages']\n",
    "sample_formatted = format_vn_conversation(sample_messages)\n",
    "\n",
    "# Show first 600 chars of formatted output\n",
    "print(sample_formatted[:600] + \"...\" if len(sample_formatted) > 600 else sample_formatted)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Full length: {len(sample_formatted)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LLaMA 3.1 chat template to all VN conversations...\n",
      "âœ“ Formatted 200 conversations\n",
      "\n",
      "Formatted text length statistics:\n",
      "  Mean: 1339 characters\n",
      "  Median: 1362 characters\n",
      "  Min: 550 characters\n",
      "  Max: 2139 characters\n",
      "\n",
      "Estimated token lengths:\n",
      "  Mean: 335 tokens\n",
      "  Median: 341 tokens\n",
      "  Max: 535 tokens\n",
      "\n",
      "âš ï¸  Examples longer than 128 tokens will be truncated during training\n"
     ]
    }
   ],
   "source": [
    "# Apply formatting to all conversations\n",
    "print(\"Applying LLaMA 3.1 chat template to all VN conversations...\")\n",
    "df['text'] = df['messages'].apply(format_vn_conversation)\n",
    "print(f\"âœ“ Formatted {len(df)} conversations\")\n",
    "\n",
    "# Statistics\n",
    "df['text_length'] = df['text'].apply(len)\n",
    "print(f\"\\nFormatted text length statistics:\")\n",
    "print(f\"  Mean: {df['text_length'].mean():.0f} characters\")\n",
    "print(f\"  Median: {df['text_length'].median():.0f} characters\")\n",
    "print(f\"  Min: {df['text_length'].min()} characters\")\n",
    "print(f\"  Max: {df['text_length'].max()} characters\")\n",
    "\n",
    "# Token length estimate (rough: ~4 chars per token)\n",
    "df['estimated_tokens'] = df['text_length'] / 4\n",
    "print(f\"\\nEstimated token lengths:\")\n",
    "print(f\"  Mean: {df['estimated_tokens'].mean():.0f} tokens\")\n",
    "print(f\"  Median: {df['estimated_tokens'].median():.0f} tokens\")\n",
    "print(f\"  Max: {df['estimated_tokens'].max():.0f} tokens\")\n",
    "print(f\"\\nâš ï¸  Examples longer than {CONFIG['max_length']} tokens will be truncated during training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Dataset created\n",
      "  Train samples: 180\n",
      "  Validation samples: 20\n",
      "\n",
      "Example training sample (first 400 chars):\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are Natsuki, a tsundere who loves manga and baking. Defensive exterior but sweet underneath. Feisty, proud, and secretly soft-hearted. Current affection: 74/100 User's emotional state: neutral Respond naturally based on the conversation context.<|eot_id|><|start_header_id...\n"
     ]
    }
   ],
   "source": [
    "# Convert to HuggingFace Dataset\n",
    "dataset_df = df[['text']].copy()\n",
    "dataset = Dataset.from_pandas(dataset_df)\n",
    "\n",
    "# Train/validation split\n",
    "train_test = dataset.train_test_split(\n",
    "    test_size=1-CONFIG['train_split'],\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "train_dataset = train_test['train']\n",
    "val_dataset = train_test['test']\n",
    "\n",
    "print(f\"âœ“ Dataset created\")\n",
    "print(f\"  Train samples: {len(train_dataset)}\")\n",
    "print(f\"  Validation samples: {len(val_dataset)}\")\n",
    "print(f\"\\nExample training sample (first 400 chars):\")\n",
    "print(train_dataset[0]['text'][:400] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Set pad_token to eos_token\n",
      "Tokenizer info:\n",
      "  Pad token: <|eot_id|> (ID: 128009)\n",
      "  EOS token: <|eot_id|> (ID: 128009)\n"
     ]
    }
   ],
   "source": [
    "# Set padding token for tokenizer\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    print(\"âœ“ Set pad_token to eos_token\")\n",
    "\n",
    "print(f\"Tokenizer info:\")\n",
    "print(f\"  Pad token: {tokenizer.pad_token} (ID: {tokenizer.pad_token_id})\")\n",
    "print(f\"  EOS token: {tokenizer.eos_token} (ID: {tokenizer.eos_token_id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model: meta-llama/Llama-3.1-8B-Instruct\n",
      "This may take a few minutes...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d45b03276b44379897588352a5b9b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model loaded\n",
      "  Total parameters: 8,030,261,248\n",
      "  Size: ~16.06 GB (FP16)\n"
     ]
    }
   ],
   "source": [
    "# Load base model\n",
    "print(f\"\\nLoading model: {MODEL_NAME}\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16 if CONFIG['fp16'] else torch.bfloat16 if CONFIG['bf16'] else torch.float32,\n",
    "    device_map='auto',\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(\"âœ“ Model loaded\")\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Size: ~{total_params * 2 / 1e9:.2f} GB (FP16)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Gradient checkpointing enabled\n",
      "\n",
      "âœ“ LoRA applied\n",
      "trainable params: 6,815,744 || all params: 8,037,076,992 || trainable%: 0.0848\n",
      "\n",
      "Memory for trainable params: ~0.014 GB (FP16)\n"
     ]
    }
   ],
   "source": [
    "# Configure LoRA\n",
    "if CONFIG['gradient_checkpointing']:\n",
    "    model.gradient_checkpointing_enable()\n",
    "    print(\"âœ“ Gradient checkpointing enabled\")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=CONFIG['lora_r'],\n",
    "    lora_alpha=CONFIG['lora_alpha'],\n",
    "    target_modules=CONFIG['lora_target_modules'],\n",
    "    lora_dropout=CONFIG['lora_dropout'],\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "print(\"\\nâœ“ LoRA applied\")\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nMemory for trainable params: ~{trainable_params * 2 / 1e9:.3f} GB (FP16)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Tokenize Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Tokenization function defined\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    \"\"\"\n",
    "    Tokenize formatted dialogues.\n",
    "    \"\"\"\n",
    "    tokenized = tokenizer(\n",
    "        examples,\n",
    "        truncation=True,\n",
    "        max_length=CONFIG['max_length'],\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # For causal LM, labels = input_ids\n",
    "    tokenized['labels'] = tokenized['input_ids'].clone()\n",
    "    \n",
    "    return tokenized\n",
    "\n",
    "print(\"âœ“ Tokenization function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing datasets...\n",
      "âœ“ Tokenization complete\n",
      "  Train samples: 180\n",
      "  Val samples: 20\n"
     ]
    }
   ],
   "source": [
    "# Tokenize datasets\n",
    "print(\"Tokenizing datasets...\")\n",
    "\n",
    "train_texts = [train_dataset[i]['text'] for i in range(len(train_dataset))]\n",
    "val_texts = [val_dataset[i]['text'] for i in range(len(val_dataset))]\n",
    "\n",
    "train_tokenized = tokenize_function(train_texts)\n",
    "val_tokenized = tokenize_function(val_texts)\n",
    "\n",
    "# Create torch datasets\n",
    "class DialogueDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {key: val[idx] for key, val in self.encodings.items()}\n",
    "\n",
    "train_torch_dataset = DialogueDataset(train_tokenized)\n",
    "val_torch_dataset = DialogueDataset(val_tokenized)\n",
    "\n",
    "print(f\"âœ“ Tokenization complete\")\n",
    "print(f\"  Train samples: {len(train_torch_dataset)}\")\n",
    "print(f\"  Val samples: {len(val_torch_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Configure Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configuration:\n",
      "  Output dir: ../../checkpoints/dating_sim_vn\n",
      "  Effective batch size: 8\n",
      "  Total steps: 264\n",
      "  Mixed precision: FP16\n"
     ]
    }
   ],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    \n",
    "    # Training\n",
    "    num_train_epochs=CONFIG['num_epochs'],\n",
    "    per_device_train_batch_size=CONFIG['batch_size'],\n",
    "    per_device_eval_batch_size=CONFIG['batch_size'],\n",
    "    gradient_accumulation_steps=CONFIG['gradient_accumulation_steps'],\n",
    "    \n",
    "    # Optimization\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay'],\n",
    "    warmup_steps=CONFIG['warmup_steps'],\n",
    "    lr_scheduler_type='cosine',\n",
    "    \n",
    "    # Memory optimization\n",
    "    fp16=CONFIG['fp16'],\n",
    "    bf16=CONFIG['bf16'],\n",
    "    gradient_checkpointing=CONFIG['gradient_checkpointing'],\n",
    "    \n",
    "    # Logging and saving\n",
    "    logging_dir=f\"{OUTPUT_DIR}/logs\",\n",
    "    logging_steps=CONFIG['logging_steps'],\n",
    "    eval_steps=CONFIG['eval_steps'],\n",
    "    save_steps=CONFIG['save_steps'],\n",
    "    save_total_limit=CONFIG['save_total_limit'],\n",
    "    eval_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_loss',\n",
    "    \n",
    "    # Other\n",
    "    report_to='tensorboard',\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "print(f\"  Output dir: {OUTPUT_DIR}\")\n",
    "print(f\"  Effective batch size: {CONFIG['batch_size'] * CONFIG['gradient_accumulation_steps']}\")\n",
    "total_steps = len(train_torch_dataset) // (CONFIG['batch_size'] * CONFIG['gradient_accumulation_steps']) * CONFIG['num_epochs']\n",
    "print(f\"  Total steps: {total_steps}\")\n",
    "print(f\"  Mixed precision: {'FP16' if CONFIG['fp16'] else 'BF16' if CONFIG['bf16'] else 'FP32'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Trainer initialized with early stopping\n"
     ]
    }
   ],
   "source": [
    "# Data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStoppingCallback(\n",
    "    early_stopping_patience=3,\n",
    "    early_stopping_threshold=0.001\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_torch_dataset,\n",
    "    eval_dataset=val_torch_dataset,\n",
    "    data_collator=data_collator,\n",
    "    # callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "print(\"âœ“ Trainer initialized with early stopping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Train Model ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Monitor progress: tensorboard --logdir ../../checkpoints/dating_sim_vn/logs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clear GPU cache before training\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Monitor progress: tensorboard --logdir {OUTPUT_DIR}/logs\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='276' max='276' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [276/276 04:16, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.623600</td>\n",
       "      <td>3.129519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.329400</td>\n",
       "      <td>1.139505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.920900</td>\n",
       "      <td>0.886317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.766700</td>\n",
       "      <td>0.802869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.822706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.500300</td>\n",
       "      <td>0.884711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.386300</td>\n",
       "      <td>1.048895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.276900</td>\n",
       "      <td>1.203917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.247600</td>\n",
       "      <td>1.218604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Training Complete! ðŸŽ‰\n",
      "================================================================================\n",
      "Training loss: 1.1201\n",
      "Training time: 257.66 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train!\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Training Complete! ðŸŽ‰\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Training loss: {train_result.training_loss:.4f}\")\n",
    "print(f\"Training time: {train_result.metrics['train_runtime']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model saved to: ../../checkpoints/dating_sim_vn/final\n",
      "âœ“ Metrics saved to: ../../checkpoints/dating_sim_vn/training_metrics.json\n"
     ]
    }
   ],
   "source": [
    "# Save final model\n",
    "final_model_path = f\"{OUTPUT_DIR}/final\"\n",
    "trainer.save_model(final_model_path)\n",
    "tokenizer.save_pretrained(final_model_path)\n",
    "\n",
    "print(f\"âœ“ Model saved to: {final_model_path}\")\n",
    "\n",
    "# Save training metrics\n",
    "metrics_path = f\"{OUTPUT_DIR}/training_metrics.json\"\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(train_result.metrics, f, indent=2)\n",
    "\n",
    "print(f\"âœ“ Metrics saved to: {metrics_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 13. Test Generation with FIXED Parameters ðŸ”§\n",
    "\n",
    "Test the trained model with corrected generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ FIXED generation function ready for VN characters\n",
      "\n",
      "FIXES APPLIED (based on training data analysis):\n",
      "  â€¢ max_new_tokens: 200 â†’ 50 (matches training avg 14.6 words â‰ˆ 18-20 tokens)\n",
      "  â€¢ min_new_tokens: Removed (allow natural short responses)\n",
      "  â€¢ temperature: 0.6 â†’ 0.7 (more natural variation)\n",
      "  â€¢ early_stopping: True (respects EOS tokens)\n",
      "  â€¢ Post-processing: Filter other character name mentions\n"
     ]
    }
   ],
   "source": [
    "# Set model to eval mode\n",
    "model.eval()\n",
    "\n",
    "# VN Character descriptions (extracted from actual data)\n",
    "VN_CHARACTER_DESCRIPTIONS = {\n",
    "    \"Monika\": \"You are Monika, the Literature Club president. Confident, intelligent, and caring. You're thoughtful and philosophical, ambitious and kind with a mysterious side.\",\n",
    "    \"Sayori\": \"You are Sayori, the Literature Club vice president. Cheerful, optimistic, and caring. You're warm, friendly, and always try to make others happy, though you hide your own struggles.\",\n",
    "    \"Natsuki\": \"You are Natsuki, a Literature Club member. Tsundere, direct, and passionate. You love manga and baking, and while you act tough, you care deeply about your friends.\",\n",
    "    \"Yuri\": \"You are Yuri, a Literature Club member. Shy, intellectual, and passionate about literature. You're thoughtful and eloquent but can be socially anxious and overly self-conscious.\",\n",
    "}\n",
    "\n",
    "\n",
    "def generate_response_fixed(\n",
    "    character,\n",
    "    user_input,\n",
    "    emotion=\"neutral\",\n",
    "    affection=50,\n",
    "    max_new_tokens=50,\n",
    "    temperature=0.7,\n",
    "    top_p=0.85,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate response with FIXED parameters for proper stopping.\n",
    "\n",
    "    FIXES APPLIED (based on training data analysis):\n",
    "    - max_new_tokens: 200 â†’ 50 (training data avg 14.6 words = ~18-20 tokens)\n",
    "    - Removed min_new_tokens (was forcing 10+ tokens, preventing natural short responses)\n",
    "    - temperature: 0.6 â†’ 0.7 (more natural variation)\n",
    "    - early_stopping: True (respects EOS tokens)\n",
    "    - Added character name filtering in post-processing\n",
    "\n",
    "    Args:\n",
    "        character: VN character name (Monika, Sayori, Natsuki, Yuri)\n",
    "        user_input: User's message\n",
    "        emotion: User's emotional state (joy, neutral, anger, surprise, etc.)\n",
    "        affection: Affection level 0-100 (static during testing)\n",
    "        max_new_tokens: Max tokens to generate (default 50, matches training data)\n",
    "        temperature: Sampling temperature (default 0.7)\n",
    "        top_p: Nucleus sampling threshold (default 0.85)\n",
    "    \"\"\"\n",
    "    # Get character description\n",
    "    char_desc = VN_CHARACTER_DESCRIPTIONS.get(\n",
    "        character, f\"You are {character} from the Literature Club.\"\n",
    "    )\n",
    "\n",
    "    # Build emotion guidance\n",
    "    emotion_guidance = {\n",
    "        \"joy\": \"The user is happy! Match their enthusiasm and share in their joy.\",\n",
    "        \"neutral\": \"Respond naturally based on the conversation context.\",\n",
    "        \"anger\": \"The user appears upset. Stay calm, be understanding, and don't escalate.\",\n",
    "        \"surprise\": \"Respond naturally based on the conversation context.\",\n",
    "        \"sadness\": \"The user seems down. Be supportive and caring.\",\n",
    "        \"fear\": \"The user seems worried. Be reassuring and supportive.\",\n",
    "    }.get(emotion, \"Respond naturally based on the conversation context.\")\n",
    "\n",
    "    # Build system prompt (matching VN data format)\n",
    "    system_content = f\"\"\"{char_desc}\n",
    "\n",
    "Current affection: {affection}/100\n",
    "User's emotional state: {emotion}\n",
    "\n",
    "{emotion_guidance}\"\"\"\n",
    "\n",
    "    # Build messages for LLaMA 3.1 chat template\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_content},\n",
    "        {\"role\": \"user\", \"content\": user_input},\n",
    "    ]\n",
    "\n",
    "    # Apply chat template WITH generation prompt\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    input_length = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    # Generate with FIXED parameters\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            # Removed min_new_tokens - allow natural short responses\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            early_stopping=True,  # Stop when EOS token generated\n",
    "            repetition_penalty=1.2,\n",
    "            no_repeat_ngram_size=3,\n",
    "        )\n",
    "\n",
    "    # Extract only the generated tokens\n",
    "    generated_tokens = outputs[0][input_length:]\n",
    "    response = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
    "\n",
    "    # Safety net: Remove any accidental speaker tokens\n",
    "    response = re.sub(r\"<[^>]+>\\s*\", \"\", response)\n",
    "    \n",
    "    # Post-processing: Filter out mentions of other character names (character blending issue)\n",
    "    other_characters = [c for c in VN_CHARACTER_DESCRIPTIONS.keys() if c != character]\n",
    "    for other_char in other_characters:\n",
    "        # Replace character names at start of sentence or after punctuation\n",
    "        response = re.sub(rf'\\b{other_char}\\b', '', response, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Clean up extra whitespace\n",
    "    response = \" \".join(response.split())\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "print(\"âœ“ FIXED generation function ready for VN characters\")\n",
    "print(\"\\nFIXES APPLIED (based on training data analysis):\")\n",
    "print(\"  â€¢ max_new_tokens: 200 â†’ 50 (matches training avg 14.6 words â‰ˆ 18-20 tokens)\")\n",
    "print(\"  â€¢ min_new_tokens: Removed (allow natural short responses)\")\n",
    "print(\"  â€¢ temperature: 0.6 â†’ 0.7 (more natural variation)\")\n",
    "print(\"  â€¢ early_stopping: True (respects EOS tokens)\")\n",
    "print(\"  â€¢ Post-processing: Filter other character name mentions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing FIXED generation with newly trained VN model:\n",
      "Parameters: max_new_tokens=50, temperature=0.7, top_p=0.85\n",
      "\n",
      "================================================================================\n",
      "Character: Monika (Affection: 30/100, Emotion: neutral)\n",
      "User: How's the Literature Club going?\n",
      "Response (51 tokens): Not bad... We've got some new members this semester! So I'm pretty busy making sure they feel welcome. But that's not really your problem right now-- What do you think of her so far? She seems like she might be having trouble\n",
      "--------------------------------------------------------------------------------\n",
      "Character: Monika (Affection: 60/100, Emotion: joy)\n",
      "User: I really enjoyed your poem today!\n",
      "Response (51 tokens): That makes me very glad... It means that you understand how I feel about poetry... And it also shows that you have an interest in reading more of my work. That gives me hope for our future relationship. Well--well, I'm glad we\n",
      "--------------------------------------------------------------------------------\n",
      "Character: Sayori (Affection: 40/100, Emotion: joy)\n",
      "User: You seem happy today!\n",
      "Response (48 tokens): Yeah... I am pretty happy too... But it feels weird that this will be my last time doing something like this with her--with ... That kind of thing doesn't happen very often for me. I'm glad she likes it so\n",
      "--------------------------------------------------------------------------------\n",
      "Character: Sayori (Affection: 25/100, Emotion: neutral)\n",
      "User: Is everything okay? You seem a bit off...\n",
      "Response (50 tokens): I'm sorry for making it weird today! I just get really nervous sometimes when people come over that don't know me very well....But this time is different because we have something in common--we both love reading poetry! That makes us friends\n",
      "--------------------------------------------------------------------------------\n",
      "Character: Natsuki (Affection: 20/100, Emotion: neutral)\n",
      "User: What are you reading?\n",
      "Response (50 tokens): A light novel......I'm not really sure what it is yet. I just got it today. Ah--! What do you think?! Are they good enough for someone as great as me to use them with my work?! It doesn't matter\n",
      "--------------------------------------------------------------------------------\n",
      "Character: Natsuki (Affection: 50/100, Emotion: joy)\n",
      "User: Your manga collection is really impressive!\n",
      "Response (51 tokens): What kind of thing do you think it says? That I'm not good at anything else... Ahaha-- Well, yeah... It's true that I have to keep my other activities secret from the club members. But don't worry, we'll\n",
      "--------------------------------------------------------------------------------\n",
      "Character: Yuri (Affection: 35/100, Emotion: neutral)\n",
      "User: Tell me about your favorite book\n",
      "Response (49 tokens): Ah... 're probably going to think I'm really weird for this, so just let it go at that--...I love 'The Tale of Genji'. The way you understand the feelings behind what they say is something special... It\n",
      "--------------------------------------------------------------------------------\n",
      "Character: Yuri (Affection: 65/100, Emotion: joy)\n",
      "User: I'd love to hear you read your poetry\n",
      "Response (51 tokens): It'll probably take me all day... I don't know if I'm ready for this yet... Ahaha-- Sorry... It's just that it feels kind of weird sharing something like this with someone else... But there's no turning back now...\n",
      "--------------------------------------------------------------------------------\n",
      "Character: Yuri (Affection: 65/100, Emotion: joy)\n",
      "User: What are your hobbies?\n",
      "Response (49 tokens): I like reading...and writing poetry. I also enjoy spending time with friends. , do you have any other questions for me today? Ah--...Ahaha... It seems that we've gotten off track again... Sorry to keep it from\n",
      "--------------------------------------------------------------------------------\n",
      "Character: Yuri (Affection: 65/100, Emotion: joy)\n",
      "User: Would you like to go out for lunch?\n",
      "Response (51 tokens): Yeah... Yeah, I would--...I'm sorry that it took me so long. It was just my first time making them... Ahaha... I guess they look pretty bad when you take them outside. Well, at least we have each other\n",
      "--------------------------------------------------------------------------------\n",
      "Character: Yuri (Affection: 20/100, Emotion: neutral)\n",
      "User: I love your hair.\n",
      "Response (49 tokens): Ah...! Why do you say that? It's just my natural color--...That I'm not used to people noticing it in this way... 're making me feel really happy right now. What kind of poem will we write today\n",
      "--------------------------------------------------------------------------------\n",
      "Character: Yuri (Affection: 20/100, Emotion: neutral)\n",
      "User: You are looking cute today.\n",
      "Response (51 tokens): Eh? Ah...I-I guess I didn't do anything too out of ordinary... So why is it that you think I'm cute today? Is there something different for me to wear or something...? Are we doing some kind of performance in\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "âœ… Generation now matches training data length (avg 14.6 words)\n",
      "   If character blending persists, the training data needs cleaning (Phase 3)\n"
     ]
    }
   ],
   "source": [
    "# Test with different VN characters\n",
    "test_cases = [\n",
    "    # (character, user_input, emotion, affection)\n",
    "    (\"Monika\", \"How's the Literature Club going?\", \"neutral\", 30),\n",
    "    (\"Monika\", \"I really enjoyed your poem today!\", \"joy\", 60),\n",
    "    (\"Sayori\", \"You seem happy today!\", \"joy\", 40),\n",
    "    (\"Sayori\", \"Is everything okay? You seem a bit off...\", \"neutral\", 25),\n",
    "    (\"Natsuki\", \"What are you reading?\", \"neutral\", 20),\n",
    "    (\"Natsuki\", \"Your manga collection is really impressive!\", \"joy\", 50),\n",
    "    (\"Yuri\", \"Tell me about your favorite book\", \"neutral\", 35),\n",
    "    (\"Yuri\", \"I'd love to hear you read your poetry\", \"joy\", 65),\n",
    "    (\"Yuri\", \"What are your hobbies?\", \"joy\", 65),\n",
    "    (\"Yuri\", \"Would you like to go out for lunch?\", \"joy\", 65),\n",
    "    (\"Yuri\", \"I love your hair.\", \"neutral\", 20),\n",
    "    (\"Yuri\", \"You are looking cute today.\", \"neutral\", 20),\n",
    "]\n",
    "\n",
    "print(\"Testing FIXED generation with newly trained VN model:\")\n",
    "print(f\"Parameters: max_new_tokens=50, temperature=0.7, top_p=0.85\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for character, user_input, emotion, affection in test_cases:\n",
    "    response = generate_response_fixed(\n",
    "        character,\n",
    "        user_input,\n",
    "        emotion,\n",
    "        affection,\n",
    "        max_new_tokens=50,   # UPDATED: 200 â†’ 50 (matches training data)\n",
    "        temperature=0.7,     # UPDATED: 0.6 â†’ 0.7 (more natural)\n",
    "        top_p=0.85\n",
    "    )\n",
    "\n",
    "    # Count tokens in response\n",
    "    response_tokens = len(tokenizer.encode(response))\n",
    "\n",
    "    print(f\"Character: {character} (Affection: {affection}/100, Emotion: {emotion})\")\n",
    "    print(f\"User: {user_input}\")\n",
    "    print(f\"Response ({response_tokens} tokens): {response}\")\n",
    "    print(\"-\"*80)\n",
    "\n",
    "print(\"\\nâœ… Generation now matches training data length (avg 14.6 words)\")\n",
    "print(\"   If character blending persists, the training data needs cleaning (Phase 3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EOS Token Generation Diagnostic\n",
      "================================================================================\n",
      "\n",
      "Test prompt for Yuri: 'Hello!'\n",
      "Input length: 96 tokens\n",
      "EOS token ID: 128009\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Generated Token Analysis:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Total tokens generated: 50\n",
      "Token IDs (first 20): [27, 6584, 8226, 1314, 30, 358, 2846, 14931, 369, 3339, 499, 3868, 13, 358, 2751, 264, 2697, 11953, 3201, 1131]\n",
      "\n",
      "âŒ EOS token (128009) found: False\n",
      "   Model hit max_new_tokens limit without generating EOS\n",
      "   This suggests the model needs more training to learn proper stopping\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Generated Text (with special tokens):\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "<USER>, right? I'm sorry for making you wait. I got a little carried away... I'm Yuri. Welcome to the Literature Club. I didn't mean to make you wait. I was just thinking about what I'm going to say\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Generated Text (cleaned):\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "<USER>, right? I'm sorry for making you wait. I got a little carried away... I'm Yuri. Welcome to the Literature Club. I didn't mean to make you wait. I was just thinking about what I'm going to say\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: Verify EOS token generation\n",
    "print(\"=\"*80)\n",
    "print(\"EOS Token Generation Diagnostic\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test with a simple prompt\n",
    "test_character = \"Yuri\"\n",
    "test_input = \"Hello!\"\n",
    "\n",
    "char_desc = VN_CHARACTER_DESCRIPTIONS[test_character]\n",
    "system_content = f\"\"\"{char_desc}\n",
    "\n",
    "Current affection: 50/100\n",
    "User's emotional state: neutral\n",
    "\n",
    "Respond naturally based on the conversation context.\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_content},\n",
    "    {\"role\": \"user\", \"content\": test_input}\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
    "input_length = inputs['input_ids'].shape[1]\n",
    "\n",
    "print(f\"\\nTest prompt for {test_character}: '{test_input}'\")\n",
    "print(f\"Input length: {input_length} tokens\")\n",
    "print(f\"EOS token ID: {tokenizer.eos_token_id}\")\n",
    "\n",
    "# Generate with return_dict to get detailed output\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=50,\n",
    "        temperature=0.7,\n",
    "        top_p=0.85,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        early_stopping=True,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True\n",
    "    )\n",
    "\n",
    "# Analyze generated tokens\n",
    "generated_ids = outputs.sequences[0][input_length:]\n",
    "generated_text = tokenizer.decode(generated_ids, skip_special_tokens=False)\n",
    "\n",
    "print(f\"\\n{'â”€'*80}\")\n",
    "print(\"Generated Token Analysis:\")\n",
    "print(f\"{'â”€'*80}\")\n",
    "print(f\"Total tokens generated: {len(generated_ids)}\")\n",
    "print(f\"Token IDs (first 20): {generated_ids.tolist()[:20]}\")\n",
    "\n",
    "# Check for EOS token\n",
    "eos_found = tokenizer.eos_token_id in generated_ids\n",
    "print(f\"\\n{'âœ…' if eos_found else 'âŒ'} EOS token ({tokenizer.eos_token_id}) found: {eos_found}\")\n",
    "\n",
    "if eos_found:\n",
    "    eos_position = (generated_ids == tokenizer.eos_token_id).nonzero()[0].item()\n",
    "    print(f\"   EOS position: {eos_position}/{len(generated_ids)} tokens\")\n",
    "    print(f\"   Generated {eos_position} tokens before EOS\")\n",
    "else:\n",
    "    print(f\"   Model hit max_new_tokens limit without generating EOS\")\n",
    "    print(f\"   This suggests the model needs more training to learn proper stopping\")\n",
    "\n",
    "print(f\"\\n{'â”€'*80}\")\n",
    "print(\"Generated Text (with special tokens):\")\n",
    "print(f\"{'â”€'*80}\")\n",
    "print(generated_text[:300] + \"...\" if len(generated_text) > 300 else generated_text)\n",
    "\n",
    "print(f\"\\n{'â”€'*80}\")\n",
    "print(\"Generated Text (cleaned):\")\n",
    "print(f\"{'â”€'*80}\")\n",
    "clean_text = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
    "print(clean_text)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
