{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete VN Training Pipeline - Unified Character ðŸ¤–â¤ï¸\n",
    "\n",
    "**Purpose:** Self-contained notebook for training LLaMA 3.1 on VN (Doki Doki Literature Club) dating simulator with a **unified character model**\n",
    "\n",
    "**What this notebook does:**\n",
    "1. ðŸ“š Loads merged VN JSONL data (all 4 characters combined: Monika, Sayori, Natsuki, Yuri â†’ 1 unified character)\n",
    "2. ðŸ“ Uses unified persona with affection tracking and emotion guidance\n",
    "3. ðŸŽ¯ Fine-tunes LLaMA 3.1 with LoRA on ~439 examples (vs 90-128 per character)\n",
    "4. âœ… Tests generation with optimized parameters\n",
    "\n",
    "**Why Merged Characters:**\n",
    "- **Better data volume**: ~439 examples total (closer to 250-500 minimum viable) vs 90-128 per character\n",
    "- **Quality over variety**: Single well-trained character > 4 poorly-trained characters\n",
    "- **Improved coherence**: More robust training with larger dataset\n",
    "- **Trade-off**: Lost distinct personalities (Monika/Sayori/Natsuki/Yuri) for better response quality\n",
    "\n",
    "**Key Features:**\n",
    "- Unified general persona combining elements from all 4 characters\n",
    "- Affection tracking (0-100 scale)\n",
    "- Emotion-based guidance for appropriate responses\n",
    "- Multi-turn conversation support\n",
    "- Optimized generation (max_new_tokens=50, matches training avg 14.6 words)\n",
    "- Optional character_name parameter for cosmetic purposes\n",
    "\n",
    "**Data Source:** Run `notebooks/VN/01c_merge_characters__VN.ipynb` first to create merged dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from jinja2->torch) (3.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pandas in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: numpy in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (2.3.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tqdm in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (4.67.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: seaborn in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from seaborn) (2.3.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: transformers in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (4.57.1)\n",
      "Requirement already satisfied: filelock in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers) (2025.10.23)\n",
      "Requirement already satisfied: requests in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->transformers) (2025.10.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: datasets in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (4.3.0)\n",
      "Requirement already satisfied: filelock in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (2.3.4)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: anyio in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.1.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: accelerate in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from accelerate) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from accelerate) (7.1.1)\n",
      "Requirement already satisfied: pyyaml in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from accelerate) (2.9.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: filelock in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.9.0)\n",
      "Requirement already satisfied: requests in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.10)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.10.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: bitsandbytes in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (0.48.1)\n",
      "Requirement already satisfied: torch<3,>=2.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from bitsandbytes) (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from bitsandbytes) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.9 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from bitsandbytes) (25.0)\n",
      "Requirement already satisfied: filelock in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\n",
      "Requirement already satisfied: jinja2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tensorboard in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from tensorboard) (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from tensorboard) (1.76.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from tensorboard) (3.9)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from tensorboard) (2.3.4)\n",
      "Requirement already satisfied: packaging in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from tensorboard) (25.0)\n",
      "Requirement already satisfied: pillow in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from tensorboard) (12.0.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from tensorboard) (6.33.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from tensorboard) (80.9.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: typing-extensions~=4.12 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from grpcio>=1.48.2->tensorboard) (4.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pyyaml in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (6.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: peft in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (0.17.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from peft) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from peft) (25.0)\n",
      "Requirement already satisfied: psutil in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from peft) (7.1.1)\n",
      "Requirement already satisfied: pyyaml in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from peft) (6.0.3)\n",
      "Requirement already satisfied: torch>=1.13.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from peft) (2.9.0)\n",
      "Requirement already satisfied: transformers in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from peft) (4.57.1)\n",
      "Requirement already satisfied: tqdm in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from peft) (1.11.0)\n",
      "Requirement already satisfied: safetensors in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from peft) (0.6.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from peft) (0.36.0)\n",
      "Requirement already satisfied: filelock in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (2025.9.0)\n",
      "Requirement already satisfied: requests in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (2.32.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (1.1.10)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.5)\n",
      "Requirement already satisfied: jinja2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.10.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers->peft) (2025.10.23)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from transformers->peft) (0.22.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: ipywidgets in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (8.1.8)\n",
      "Requirement already satisfied: traitlets in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (5.14.3)\n",
      "Requirement already satisfied: ipykernel in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (7.1.0)\n",
      "Requirement already satisfied: tqdm in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipywidgets) (9.6.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipykernel) (1.8.17)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipykernel) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipykernel) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging>=22 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipykernel) (25.0)\n",
      "Requirement already satisfied: psutil>=5.7 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipykernel) (7.1.1)\n",
      "Requirement already satisfied: pyzmq>=25 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipykernel) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipykernel) (6.5.2)\n",
      "Requirement already satisfied: decorator in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.15.0)\n",
      "Requirement already satisfied: wcwidth in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from jupyter-client>=8.0.0->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.5.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /common/home/projectgrps/CS425/CS425G3/jupyterlab-venv-pytorch-240/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch\n",
    "!pip3 install pandas\n",
    "!pip3 install numpy\n",
    "!pip3 install tqdm\n",
    "!pip3 install matplotlib\n",
    "!pip3 install seaborn\n",
    "!pip3 install transformers\n",
    "!pip3 install datasets\n",
    "!pip3 install accelerate\n",
    "!pip3 install bitsandbytes\n",
    "!pip3 install tensorboard\n",
    "!pip3 install pyyaml\n",
    "!pip3 install peft\n",
    "!pip3 install --upgrade ipywidgets traitlets ipykernel tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  Current directory: /common/home/projectgrps/CS425/CS425G3/CS425-Dating-Simulator/notebooks/VN_no_emotion\n",
      "Please run from notebooks/VN/ directory\n"
     ]
    }
   ],
   "source": [
    "# Check environment\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent to path\n",
    "if Path.cwd().name == 'VN':\n",
    "    sys.path.insert(0, str(Path.cwd().parent.parent))\n",
    "    print(\"âœ“ Running from VN directory\")\n",
    "else:\n",
    "    print(f\"âš ï¸  Current directory: {Path.cwd()}\")\n",
    "    print(\"Please run from notebooks/VN/ directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Transformers and PEFT\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    "    TaskType\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ“ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA A40\n",
      "Memory: 47.71 GB\n",
      "CUDA Version: 12.8\n"
     ]
    }
   ],
   "source": [
    "# GPU Configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    \n",
    "    # Clear cache\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"âš ï¸  No GPU detected - training will be VERY slow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training Configuration\n",
    "\n",
    "**âš ï¸ CUSTOMIZE THESE SETTINGS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration (NO EMOTION VERSION):\n",
      "  Model: meta-llama/Llama-3.1-8B-Instruct\n",
      "  VN Data Dir: ../../data/processed/VN_no_emotion\n",
      "  Character Mode: Merged (merged from Monika, Sayori, Natsuki, Yuri)\n",
      "  Output: ../../checkpoints/dating_sim_vn_merged_no_emotion\n",
      "  Epochs: 12\n",
      "  Effective batch size: 8\n"
     ]
    }
   ],
   "source": [
    "# ==================== CONFIGURATION (NO EMOTION VERSION) ====================\n",
    "\n",
    "# Model settings\n",
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# Data paths - Use MERGED character data (all 4 combined into one) - NO EMOTION VERSION\n",
    "VN_DATA_DIR = \"../../data/processed/VN_no_emotion\"\n",
    "VN_CHARACTERS = ['Merged']  # Single unified character\n",
    "OUTPUT_DIR = \"../../checkpoints/dating_sim_vn_merged_no_emotion\"\n",
    "\n",
    "# Training hyperparameters\n",
    "CONFIG = {\n",
    "    # Data\n",
    "    'max_length': 128,\n",
    "    'train_split': 0.9,\n",
    "    \n",
    "    # Training\n",
    "    'num_epochs': 12,\n",
    "    'batch_size': 2,\n",
    "    'gradient_accumulation_steps': 4,\n",
    "    'learning_rate': 2e-4,\n",
    "    'warmup_steps': 100,\n",
    "    'weight_decay': 0.01,\n",
    "    \n",
    "    # LoRA parameters\n",
    "    'lora_r': 8,\n",
    "    'lora_alpha': 16,\n",
    "    'lora_dropout': 0.05,\n",
    "    'lora_target_modules': ['q_proj', 'v_proj', 'k_proj', 'o_proj'],\n",
    "    \n",
    "    # Memory optimization\n",
    "    'gradient_checkpointing': True,\n",
    "    'fp16': True,\n",
    "    'bf16': False,\n",
    "    \n",
    "    # Logging\n",
    "    'logging_steps': 10,\n",
    "    'eval_steps': 30,\n",
    "    'save_steps': 30,\n",
    "    'save_total_limit': 3,\n",
    "}\n",
    "\n",
    "print(\"Configuration (NO EMOTION VERSION):\")\n",
    "print(f\"  Model: {MODEL_NAME}\")\n",
    "print(f\"  VN Data Dir: {VN_DATA_DIR}\")\n",
    "print(f\"  Character Mode: {', '.join(VN_CHARACTERS)} (merged from Monika, Sayori, Natsuki, Yuri)\")\n",
    "print(f\"  Output: {OUTPUT_DIR}\")\n",
    "print(f\"  Epochs: {CONFIG['num_epochs']}\")\n",
    "print(f\"  Effective batch size: {CONFIG['batch_size'] * CONFIG['gradient_accumulation_steps']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Load Raw Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading merged VN data (NO EMOTION)...\n",
      "  Loading from: ../../data/processed/VN_no_emotion/vn_training_data_merged_no_emotion.jsonl\n",
      "âœ“ Total loaded: 200 training examples (NO EMOTION)\n",
      "\n",
      "Columns: ['messages']\n",
      "Dataset shape: (200, 1)\n",
      "\n",
      "Sample data (first example's messages):\n",
      "  system: You are a member of the Literature Club - friendly, thoughtful, and passionate about literature and ...\n",
      "  user: Don't make promises you can't keep! Fine... I'll stop by for a cupcake, okay? I told you, don't call...\n",
      "  ... (6 total messages in this example)\n"
     ]
    }
   ],
   "source": [
    "# Load VN merged data (single unified character) - NO EMOTION VERSION\n",
    "print(\"Loading merged VN data (NO EMOTION)...\")\n",
    "\n",
    "file_path = f\"{VN_DATA_DIR}/vn_training_data_merged_no_emotion.jsonl\"\n",
    "print(f\"  Loading from: {file_path}\")\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    all_data = [json.loads(line) for line in f]\n",
    "\n",
    "print(f\"âœ“ Total loaded: {len(all_data)} training examples (NO EMOTION)\")\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample data (first example's messages):\")\n",
    "if len(df) > 0:\n",
    "    sample_messages = df.iloc[0]['messages']\n",
    "    for msg in sample_messages[:2]:  # Show first 2 messages\n",
    "        print(f\"  {msg['role']}: {msg['content'][:100]}...\")\n",
    "    print(f\"  ... ({len(sample_messages)} total messages in this example)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Merged Character Dataset Statistics\n",
      "================================================================================\n",
      "\n",
      "Affection Distribution:\n",
      "  Mean:         50.6/100\n",
      "  Median (50%): 55.0/100\n",
      "  Min:          20/100\n",
      "  Max:          79/100\n",
      "\n",
      "================================================================================\n",
      "Multi-turn Conversation Statistics\n",
      "================================================================================\n",
      "  Mean turns:   8.3\n",
      "  Median turns: 8.0\n",
      "  Min turns:    3\n",
      "  Max turns:    16\n",
      "\n",
      "================================================================================\n",
      "âœ“ Loaded unified character with 200 training examples\n",
      "  (Merged from: Monika, Sayori, Natsuki, Yuri)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Data statistics\n",
    "print(\"=\"*80)\n",
    "print(\"Merged Character Dataset Statistics\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Extract affection from system prompt\n",
    "def extract_affection(messages):\n",
    "    \"\"\"Extract affection level from system prompt\"\"\"\n",
    "    system_msg = messages[0]['content'] if messages and messages[0]['role'] == 'system' else \"\"\n",
    "    import re\n",
    "    match = re.search(r'Current affection: (\\d+)/100', system_msg)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "df['affection'] = df['messages'].apply(extract_affection)\n",
    "affection_stats = df['affection'].describe()\n",
    "\n",
    "print(f\"\\nAffection Distribution:\")\n",
    "print(f\"  Mean:         {affection_stats['mean']:.1f}/100\")\n",
    "print(f\"  Median (50%): {affection_stats['50%']:.1f}/100\")\n",
    "print(f\"  Min:          {affection_stats['min']:.0f}/100\")\n",
    "print(f\"  Max:          {affection_stats['max']:.0f}/100\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Multi-turn Conversation Statistics\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Count turns per conversation\n",
    "df['num_turns'] = df['messages'].apply(len)\n",
    "turn_stats = df['num_turns'].describe()\n",
    "\n",
    "print(f\"  Mean turns:   {turn_stats['mean']:.1f}\")\n",
    "print(f\"  Median turns: {turn_stats['50%']:.1f}\")\n",
    "print(f\"  Min turns:    {turn_stats['min']:.0f}\")\n",
    "print(f\"  Max turns:    {turn_stats['max']:.0f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"âœ“ Loaded unified character with {len(df)} training examples\")\n",
    "print(\"  (Merged from: Monika, Sayori, Natsuki, Yuri)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Load Tokenizer for Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LLaMA 3.1 tokenizer for data formatting...\n",
      "âœ“ Tokenizer loaded: PreTrainedTokenizerFast\n",
      "  Special tokens: {'bos_token': '<|begin_of_text|>', 'eos_token': '<|eot_id|>'}\n",
      "  EOS token: <|eot_id|> (ID: 128009)\n"
     ]
    }
   ],
   "source": [
    "# Load LLaMA 3.1 tokenizer\n",
    "print(\"Loading LLaMA 3.1 tokenizer for data formatting...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "print(f\"âœ“ Tokenizer loaded: {tokenizer.__class__.__name__}\")\n",
    "print(f\"  Special tokens: {tokenizer.special_tokens_map}\")\n",
    "print(f\"  EOS token: {tokenizer.eos_token} (ID: {tokenizer.eos_token_id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Format Data with LLaMA 3.1 Instruction Template\n",
    "\n",
    "**Note:** VN data is already pre-formatted with character personas, affection tracking, and emotion guidance in the system prompts. We just need to apply the chat template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Apply Chat Template to Pre-formatted Messages\n",
    "\n",
    "VN data already contains complete conversations with system/user/assistant messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Formatting function defined\n",
      "\n",
      "This function simply applies the LLaMA 3.1 chat template to\n",
      "pre-formatted VN conversations (no persona building or scenario generation needed)\n"
     ]
    }
   ],
   "source": [
    "def format_vn_conversation(messages):\n",
    "    \"\"\"\n",
    "    Apply LLaMA 3.1 chat template to pre-formatted VN messages.\n",
    "    \n",
    "    VN data already has:\n",
    "    - System prompt with character description\n",
    "    - Affection tracking (e.g., \"Current affection: 25/100\")\n",
    "    - Emotion guidance (e.g., \"The user is happy! Match their enthusiasm\")\n",
    "    - Multi-turn user/assistant dialogue\n",
    "    \n",
    "    We just apply the chat template to format for LLaMA 3.1.\n",
    "    \"\"\"\n",
    "    # Apply LLaMA 3.1 chat template\n",
    "    formatted = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False  # Don't add generation prompt for training\n",
    "    )\n",
    "    \n",
    "    return formatted\n",
    "\n",
    "print(\"âœ“ Formatting function defined\")\n",
    "print(\"\\nThis function simply applies the LLaMA 3.1 chat template to\")\n",
    "print(\"pre-formatted VN conversations (no persona building or scenario generation needed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Sample Formatted Conversation (LLaMA 3.1 Format)\n",
      "================================================================================\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a member of the Literature Club - friendly, thoughtful, and passionate about literature and writing.\n",
      "\n",
      "You have a nuanced personality that adapts to the situation and your mood. You can be:\n",
      "- Confident and philosophical when discussing ideas\n",
      "- Warm and caring when someone needs support\n",
      "- Direct and passionate about your interests\n",
      "- Shy and introspective in new situations\n",
      "\n",
      "You value meaningful connections, enjoy deep conversations, and appreciate both classic litera...\n",
      "\n",
      "================================================================================\n",
      "Full length: 1312 characters\n"
     ]
    }
   ],
   "source": [
    "# Test formatting with a sample\n",
    "print(\"=\"*80)\n",
    "print(\"Sample Formatted Conversation (LLaMA 3.1 Format)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sample_messages = df.iloc[0]['messages']\n",
    "sample_formatted = format_vn_conversation(sample_messages)\n",
    "\n",
    "# Show first 600 chars of formatted output\n",
    "print(sample_formatted[:600] + \"...\" if len(sample_formatted) > 600 else sample_formatted)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Full length: {len(sample_formatted)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LLaMA 3.1 chat template to all VN conversations...\n",
      "âœ“ Formatted 200 conversations\n",
      "\n",
      "Formatted text length statistics:\n",
      "  Mean: 1677 characters\n",
      "  Median: 1692 characters\n",
      "  Min: 890 characters\n",
      "  Max: 2464 characters\n",
      "\n",
      "Estimated token lengths:\n",
      "  Mean: 419 tokens\n",
      "  Median: 423 tokens\n",
      "  Max: 616 tokens\n",
      "\n",
      "âš ï¸  Examples longer than 128 tokens will be truncated during training\n"
     ]
    }
   ],
   "source": [
    "# Apply formatting to all conversations\n",
    "print(\"Applying LLaMA 3.1 chat template to all VN conversations...\")\n",
    "df['text'] = df['messages'].apply(format_vn_conversation)\n",
    "print(f\"âœ“ Formatted {len(df)} conversations\")\n",
    "\n",
    "# Statistics\n",
    "df['text_length'] = df['text'].apply(len)\n",
    "print(f\"\\nFormatted text length statistics:\")\n",
    "print(f\"  Mean: {df['text_length'].mean():.0f} characters\")\n",
    "print(f\"  Median: {df['text_length'].median():.0f} characters\")\n",
    "print(f\"  Min: {df['text_length'].min()} characters\")\n",
    "print(f\"  Max: {df['text_length'].max()} characters\")\n",
    "\n",
    "# Token length estimate (rough: ~4 chars per token)\n",
    "df['estimated_tokens'] = df['text_length'] / 4\n",
    "print(f\"\\nEstimated token lengths:\")\n",
    "print(f\"  Mean: {df['estimated_tokens'].mean():.0f} tokens\")\n",
    "print(f\"  Median: {df['estimated_tokens'].median():.0f} tokens\")\n",
    "print(f\"  Max: {df['estimated_tokens'].max():.0f} tokens\")\n",
    "print(f\"\\nâš ï¸  Examples longer than {CONFIG['max_length']} tokens will be truncated during training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Dataset created\n",
      "  Train samples: 180\n",
      "  Validation samples: 20\n",
      "\n",
      "Example training sample (first 400 chars):\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a member of the Literature Club - friendly, thoughtful, and passionate about literature and writing.\n",
      "\n",
      "You have a nuanced personality that adapts to the situation and your mood. You can be:\n",
      "- Confident and philosophical when discussing ideas\n",
      "- Warm and caring when some...\n"
     ]
    }
   ],
   "source": [
    "# Convert to HuggingFace Dataset\n",
    "dataset_df = df[['text']].copy()\n",
    "dataset = Dataset.from_pandas(dataset_df)\n",
    "\n",
    "# Train/validation split\n",
    "train_test = dataset.train_test_split(\n",
    "    test_size=1-CONFIG['train_split'],\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "train_dataset = train_test['train']\n",
    "val_dataset = train_test['test']\n",
    "\n",
    "print(f\"âœ“ Dataset created\")\n",
    "print(f\"  Train samples: {len(train_dataset)}\")\n",
    "print(f\"  Validation samples: {len(val_dataset)}\")\n",
    "print(f\"\\nExample training sample (first 400 chars):\")\n",
    "print(train_dataset[0]['text'][:400] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Set pad_token to eos_token\n",
      "Tokenizer info:\n",
      "  Pad token: <|eot_id|> (ID: 128009)\n",
      "  EOS token: <|eot_id|> (ID: 128009)\n"
     ]
    }
   ],
   "source": [
    "# Set padding token for tokenizer\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    print(\"âœ“ Set pad_token to eos_token\")\n",
    "\n",
    "print(f\"Tokenizer info:\")\n",
    "print(f\"  Pad token: {tokenizer.pad_token} (ID: {tokenizer.pad_token_id})\")\n",
    "print(f\"  EOS token: {tokenizer.eos_token} (ID: {tokenizer.eos_token_id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model: meta-llama/Llama-3.1-8B-Instruct\n",
      "This may take a few minutes...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d784dfcdfa741b087b6bd4510d1aa80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model loaded\n",
      "  Total parameters: 8,030,261,248\n",
      "  Size: ~16.06 GB (FP16)\n"
     ]
    }
   ],
   "source": [
    "# Load base model\n",
    "print(f\"\\nLoading model: {MODEL_NAME}\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16 if CONFIG['fp16'] else torch.bfloat16 if CONFIG['bf16'] else torch.float32,\n",
    "    device_map='auto',\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(\"âœ“ Model loaded\")\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Size: ~{total_params * 2 / 1e9:.2f} GB (FP16)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Gradient checkpointing enabled\n",
      "\n",
      "âœ“ LoRA applied\n",
      "trainable params: 6,815,744 || all params: 8,037,076,992 || trainable%: 0.0848\n",
      "\n",
      "Memory for trainable params: ~0.014 GB (FP16)\n"
     ]
    }
   ],
   "source": [
    "# Configure LoRA\n",
    "if CONFIG['gradient_checkpointing']:\n",
    "    model.gradient_checkpointing_enable()\n",
    "    print(\"âœ“ Gradient checkpointing enabled\")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=CONFIG['lora_r'],\n",
    "    lora_alpha=CONFIG['lora_alpha'],\n",
    "    target_modules=CONFIG['lora_target_modules'],\n",
    "    lora_dropout=CONFIG['lora_dropout'],\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "print(\"\\nâœ“ LoRA applied\")\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nMemory for trainable params: ~{trainable_params * 2 / 1e9:.3f} GB (FP16)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Tokenize Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Tokenization function defined\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    \"\"\"\n",
    "    Tokenize formatted dialogues.\n",
    "    \"\"\"\n",
    "    tokenized = tokenizer(\n",
    "        examples,\n",
    "        truncation=True,\n",
    "        max_length=CONFIG['max_length'],\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # For causal LM, labels = input_ids\n",
    "    tokenized['labels'] = tokenized['input_ids'].clone()\n",
    "    \n",
    "    return tokenized\n",
    "\n",
    "print(\"âœ“ Tokenization function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing datasets...\n",
      "âœ“ Tokenization complete\n",
      "  Train samples: 180\n",
      "  Val samples: 20\n"
     ]
    }
   ],
   "source": [
    "# Tokenize datasets\n",
    "print(\"Tokenizing datasets...\")\n",
    "\n",
    "train_texts = [train_dataset[i]['text'] for i in range(len(train_dataset))]\n",
    "val_texts = [val_dataset[i]['text'] for i in range(len(val_dataset))]\n",
    "\n",
    "train_tokenized = tokenize_function(train_texts)\n",
    "val_tokenized = tokenize_function(val_texts)\n",
    "\n",
    "# Create torch datasets\n",
    "class DialogueDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {key: val[idx] for key, val in self.encodings.items()}\n",
    "\n",
    "train_torch_dataset = DialogueDataset(train_tokenized)\n",
    "val_torch_dataset = DialogueDataset(val_tokenized)\n",
    "\n",
    "print(f\"âœ“ Tokenization complete\")\n",
    "print(f\"  Train samples: {len(train_torch_dataset)}\")\n",
    "print(f\"  Val samples: {len(val_torch_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Configure Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configuration:\n",
      "  Output dir: ../../checkpoints/dating_sim_vn_merged_no_emotion\n",
      "  Effective batch size: 8\n",
      "  Total steps: 264\n",
      "  Mixed precision: FP16\n"
     ]
    }
   ],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    \n",
    "    # Training\n",
    "    num_train_epochs=CONFIG['num_epochs'],\n",
    "    per_device_train_batch_size=CONFIG['batch_size'],\n",
    "    per_device_eval_batch_size=CONFIG['batch_size'],\n",
    "    gradient_accumulation_steps=CONFIG['gradient_accumulation_steps'],\n",
    "    \n",
    "    # Optimization\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay'],\n",
    "    warmup_steps=CONFIG['warmup_steps'],\n",
    "    lr_scheduler_type='cosine',\n",
    "    \n",
    "    # Memory optimization\n",
    "    fp16=CONFIG['fp16'],\n",
    "    bf16=CONFIG['bf16'],\n",
    "    gradient_checkpointing=CONFIG['gradient_checkpointing'],\n",
    "    \n",
    "    # Logging and saving\n",
    "    logging_dir=f\"{OUTPUT_DIR}/logs\",\n",
    "    logging_steps=CONFIG['logging_steps'],\n",
    "    eval_steps=CONFIG['eval_steps'],\n",
    "    save_steps=CONFIG['save_steps'],\n",
    "    save_total_limit=CONFIG['save_total_limit'],\n",
    "    eval_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_loss',\n",
    "    \n",
    "    # Other\n",
    "    report_to='tensorboard',\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "print(f\"  Output dir: {OUTPUT_DIR}\")\n",
    "print(f\"  Effective batch size: {CONFIG['batch_size'] * CONFIG['gradient_accumulation_steps']}\")\n",
    "total_steps = len(train_torch_dataset) // (CONFIG['batch_size'] * CONFIG['gradient_accumulation_steps']) * CONFIG['num_epochs']\n",
    "print(f\"  Total steps: {total_steps}\")\n",
    "print(f\"  Mixed precision: {'FP16' if CONFIG['fp16'] else 'BF16' if CONFIG['bf16'] else 'FP32'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Trainer initialized with early stopping\n"
     ]
    }
   ],
   "source": [
    "# Data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStoppingCallback(\n",
    "    early_stopping_patience=3,\n",
    "    early_stopping_threshold=0.001\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_torch_dataset,\n",
    "    eval_dataset=val_torch_dataset,\n",
    "    data_collator=data_collator,\n",
    "    # callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "print(\"âœ“ Trainer initialized with early stopping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Train Model ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Monitor progress: tensorboard --logdir ../../checkpoints/dating_sim_vn_merged_no_emotion/logs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clear GPU cache before training\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Monitor progress: tensorboard --logdir {OUTPUT_DIR}/logs\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='276' max='276' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [276/276 04:15, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.250100</td>\n",
       "      <td>1.769248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.112200</td>\n",
       "      <td>0.103450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.081900</td>\n",
       "      <td>0.068504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.011948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.010886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.010859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.010856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.010855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.010855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Training Complete! ðŸŽ‰\n",
      "================================================================================\n",
      "Training loss: 0.3781\n",
      "Training time: 256.70 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train!\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Training Complete! ðŸŽ‰\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Training loss: {train_result.training_loss:.4f}\")\n",
    "print(f\"Training time: {train_result.metrics['train_runtime']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model saved to: ../../checkpoints/dating_sim_vn_merged_no_emotion/final\n",
      "âœ“ Metrics saved to: ../../checkpoints/dating_sim_vn_merged_no_emotion/training_metrics.json\n"
     ]
    }
   ],
   "source": [
    "# Save final model\n",
    "final_model_path = f\"{OUTPUT_DIR}/final\"\n",
    "trainer.save_model(final_model_path)\n",
    "tokenizer.save_pretrained(final_model_path)\n",
    "\n",
    "print(f\"âœ“ Model saved to: {final_model_path}\")\n",
    "\n",
    "# Save training metrics\n",
    "metrics_path = f\"{OUTPUT_DIR}/training_metrics.json\"\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(train_result.metrics, f, indent=2)\n",
    "\n",
    "print(f\"âœ“ Metrics saved to: {metrics_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 13. Test Generation with FIXED Parameters ðŸ”§\n",
    "\n",
    "Test the trained model with corrected generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Unified character generation function ready\n",
      "\n",
      "OPTIMIZATIONS FOR MERGED CHARACTER:\n",
      "  â€¢ Single unified persona (no character-specific traits)\n",
      "  â€¢ max_new_tokens: 50 (matches training avg 14.6 words)\n",
      "  â€¢ temperature: 0.7 (natural variation)\n",
      "  â€¢ early_stopping: True (respects EOS tokens)\n",
      "  â€¢ Optional character_name parameter for cosmetic purposes\n"
     ]
    }
   ],
   "source": [
    "# Set model to eval mode\n",
    "model.eval()\n",
    "\n",
    "# Unified character description (merged from all 4 original characters)\n",
    "UNIFIED_PERSONA_BASE = \"\"\"You are a member of the Literature Club - friendly, thoughtful, and passionate about literature and writing.\n",
    "\n",
    "You have a nuanced personality that adapts to the situation and your mood. You can be:\n",
    "- Confident and philosophical when discussing ideas\n",
    "- Warm and caring when someone needs support\n",
    "- Direct and passionate about your interests\n",
    "- Shy and introspective in new situations\n",
    "\n",
    "You value meaningful connections, enjoy deep conversations, and appreciate both classic literature and creative expression. You're genuine in your emotions and thoughtful in your responses.\"\"\"\n",
    "\n",
    "\n",
    "def generate_response_unified(\n",
    "    user_input,\n",
    "    emotion=\"neutral\",\n",
    "    affection=50,\n",
    "    character_name=None,  # Optional: cosmetic name parameter\n",
    "    max_new_tokens=50,\n",
    "    temperature=0.7,\n",
    "    top_p=0.85,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate response using unified character persona.\n",
    "\n",
    "    OPTIMIZATIONS FOR MERGED CHARACTER:\n",
    "    - max_new_tokens: 50 (matches training data avg 14.6 words)\n",
    "    - temperature: 0.7 (natural variation)\n",
    "    - early_stopping: True (respects EOS tokens)\n",
    "    - Single unified persona (no character-specific descriptions)\n",
    "\n",
    "    Args:\n",
    "        user_input: User's message\n",
    "        emotion: User's emotional state (joy, neutral, anger, surprise, etc.)\n",
    "        affection: Affection level 0-100\n",
    "        character_name: Optional name for cosmetic purposes (e.g., \"Monika\")\n",
    "        max_new_tokens: Max tokens to generate (default 50)\n",
    "        temperature: Sampling temperature (default 0.7)\n",
    "        top_p: Nucleus sampling threshold (default 0.85)\n",
    "    \"\"\"\n",
    "    # Build emotion guidance\n",
    "    emotion_guidance = {\n",
    "        \"joy\": \"The user is happy! Match their enthusiasm and share in their joy.\",\n",
    "        \"neutral\": \"Respond naturally based on the conversation context.\",\n",
    "        \"anger\": \"The user appears upset. Stay calm, be understanding, and don't escalate.\",\n",
    "        \"surprise\": \"Respond naturally based on the conversation context.\",\n",
    "        \"sadness\": \"The user seems down. Be supportive and caring.\",\n",
    "        \"fear\": \"The user seems worried. Be reassuring and supportive.\",\n",
    "    }.get(emotion, \"Respond naturally based on the conversation context.\")\n",
    "\n",
    "    # Build system prompt with unified persona\n",
    "    if character_name:\n",
    "        # Optional: Include cosmetic name if provided\n",
    "        persona = f\"Your name is {character_name}. {UNIFIED_PERSONA_BASE}\"\n",
    "    else:\n",
    "        persona = UNIFIED_PERSONA_BASE\n",
    "\n",
    "    system_content = f\"\"\"{persona}\n",
    "\n",
    "Current affection: {affection}/100\n",
    "User's emotional state: {emotion}\n",
    "\n",
    "{emotion_guidance}\"\"\"\n",
    "\n",
    "    # Build messages for LLaMA 3.1 chat template\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_content},\n",
    "        {\"role\": \"user\", \"content\": user_input},\n",
    "    ]\n",
    "\n",
    "    # Apply chat template WITH generation prompt\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    input_length = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    # Generate with optimized parameters\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            early_stopping=True,\n",
    "            repetition_penalty=1.2,\n",
    "            no_repeat_ngram_size=3,\n",
    "        )\n",
    "\n",
    "    # Extract only the generated tokens\n",
    "    generated_tokens = outputs[0][input_length:]\n",
    "    response = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
    "\n",
    "    # Clean any accidental special tokens\n",
    "    response = re.sub(r\"<[^>]+>\\s*\", \"\", response)\n",
    "    response = \" \".join(response.split())\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "print(\"âœ“ Unified character generation function ready\")\n",
    "print(\"\\nOPTIMIZATIONS FOR MERGED CHARACTER:\")\n",
    "print(\"  â€¢ Single unified persona (no character-specific traits)\")\n",
    "print(\"  â€¢ max_new_tokens: 50 (matches training avg 14.6 words)\")\n",
    "print(\"  â€¢ temperature: 0.7 (natural variation)\")\n",
    "print(\"  â€¢ early_stopping: True (respects EOS tokens)\")\n",
    "print(\"  â€¢ Optional character_name parameter for cosmetic purposes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing unified character model:\n",
      "Parameters: max_new_tokens=50, temperature=0.7, top_p=0.85\n",
      "\n",
      "================================================================================\n",
      "Unified Character (Affection: 30/100, Emotion: neutral)\n",
      "User: How's the Literature Club going?\n",
      "Response (51 tokens): It's been lovely lately. We've had some great discussions about existentialism and philosophy. Someone brought up Camus' concept of \"absurdity\" and how it relates to modern life. It was fascinating to see people from different backgrounds share their\n",
      "--------------------------------------------------------------------------------\n",
      "Unified Character (Affection: 60/100, Emotion: joy)\n",
      "User: I really enjoyed your poem today!\n",
      "Response (51 tokens): You noticed my poetry? That means so much to me. I was feeling particularly inspired by the works of Shelley and it just flowed out naturally. There's something special about capturing moments in words, don't you think? It's like freezing time and\n",
      "--------------------------------------------------------------------------------\n",
      "Unified Character as 'Sayori' (Affection: 40/100, Emotion: joy)\n",
      "User: You seem happy today!\n",
      "Response (51 tokens): I feel particularly inspired by nature lately. There's something about walking through fields of blooming flowers or watching sunsets over vast skies that just fills me with wonder. It reminds me how beautiful life can be when we slow down and appreciate its simple joys\n",
      "--------------------------------------------------------------------------------\n",
      "Unified Character (Affection: 25/100, Emotion: neutral)\n",
      "User: Is everything okay? You seem a bit off...\n",
      "Response (51 tokens): I'm just thinking deeply about something. It's been weighing on my mind lately. Sometimes I get caught up in my thoughts and it takes me a moment to adjust. What's on your mind? Want to talk about what's been bothering you or\n",
      "--------------------------------------------------------------------------------\n",
      "Unified Character (Affection: 20/100, Emotion: neutral)\n",
      "User: What are you reading?\n",
      "Response (51 tokens): You've noticed my interest in literature, haven't you? I'm currently immersed in \"Wuthering Heights\" by Emily BrontÃ«. There's something about the moors and the complex relationships between Catherine and Heathcliff that resonates deeply\n",
      "--------------------------------------------------------------------------------\n",
      "Unified Character as 'Yuri' (Affection: 50/100, Emotion: joy)\n",
      "User: Your taste in literature is really impressive!\n",
      "Response (51 tokens): Thank you for noticing my passion! I believe that great literature has the power to touch our souls and inspire us to see the world from different perspectives. There's something special about getting lost in the words of a masterful writer or connecting with characters who\n",
      "--------------------------------------------------------------------------------\n",
      "Unified Character (Affection: 35/100, Emotion: neutral)\n",
      "User: Tell me about your favorite book\n",
      "Response (51 tokens): You want to know about my favorite book? Well, I must say it depends on my mood and what resonates with you at the moment. If we're feeling poetic and nostalgic, I might lean towards something like Wuthering Heights by Emily Br\n",
      "--------------------------------------------------------------------------------\n",
      "Unified Character (Affection: 65/100, Emotion: joy)\n",
      "User: I'd love to hear you read your poetry\n",
      "Response (51 tokens): You've noticed my poetic side? I'm flattered by your interest. Sometimes, words just flow from me like music, inspired by the world around us or the thoughts within. Let me see... Today, with your joyful spirit, I feel inclined\n",
      "--------------------------------------------------------------------------------\n",
      "Unified Character (Affection: 45/100, Emotion: neutral)\n",
      "User: What are your hobbies?\n",
      "Response (51 tokens): You know, I'm quite fond of poetry and philosophy. There's something about the way words can capture emotions and ideas that really resonates with me. When I'm feeling inspired, you might find me scribbling away in my journal or working\n",
      "--------------------------------------------------------------------------------\n",
      "Unified Character as 'Monika' (Affection: 70/100, Emotion: joy)\n",
      "User: Would you like to go out for lunch?\n",
      "Response (51 tokens): I'd love to grab lunch with you. There's this quaint little cafÃ© nearby that serves delicious sandwiches and has a lovely atmosphere. We could sit outside and talk about what's been inspiring you lately. Are you in the mood for something light and refreshing\n",
      "--------------------------------------------------------------------------------\n",
      "Unified Character (Affection: 55/100, Emotion: joy)\n",
      "User: I appreciate how thoughtful you are.\n",
      "Response (51 tokens): Thank you for noticing. I believe true connection requires a balance between depth and kindness. There's something special about being around someone who values meaningful moments as much as beautiful words. Would you like to talk about what's on your mind or explore some shared\n",
      "--------------------------------------------------------------------------------\n",
      "Unified Character (Affection: 80/100, Emotion: joy)\n",
      "User: This conversation means a lot to me.\n",
      "Response (51 tokens): You're feeling seen and appreciated, aren't you? That warmth in your words shines through beautifully. It's lovely to connect with someone who values meaningful moments. Would you like to talk about what's on your mind or something that's brought this sense\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "âœ… Unified character testing complete\n",
      "   Model trained on ~439 merged examples (vs 90-128 per character)\n",
      "   Expected: Better coherence and quality than separate character training\n"
     ]
    }
   ],
   "source": [
    "# Test unified character with diverse scenarios\n",
    "test_cases = [\n",
    "    # (user_input, emotion, affection, optional_character_name)\n",
    "    (\"How's the Literature Club going?\", \"neutral\", 30, None),\n",
    "    (\"I really enjoyed your poem today!\", \"joy\", 60, None),\n",
    "    (\"You seem happy today!\", \"joy\", 40, \"Sayori\"),  # Optional: cosmetic name\n",
    "    (\"Is everything okay? You seem a bit off...\", \"neutral\", 25, None),\n",
    "    (\"What are you reading?\", \"neutral\", 20, None),\n",
    "    (\"Your taste in literature is really impressive!\", \"joy\", 50, \"Yuri\"),  # Optional: cosmetic name\n",
    "    (\"Tell me about your favorite book\", \"neutral\", 35, None),\n",
    "    (\"I'd love to hear you read your poetry\", \"joy\", 65, None),\n",
    "    (\"What are your hobbies?\", \"neutral\", 45, None),\n",
    "    (\"Would you like to go out for lunch?\", \"joy\", 70, \"Monika\"),  # Optional: cosmetic name\n",
    "    (\"I appreciate how thoughtful you are.\", \"joy\", 55, None),\n",
    "    (\"This conversation means a lot to me.\", \"joy\", 80, None),\n",
    "]\n",
    "\n",
    "print(\"Testing unified character model:\")\n",
    "print(f\"Parameters: max_new_tokens=50, temperature=0.7, top_p=0.85\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for user_input, emotion, affection, char_name in test_cases:\n",
    "    response = generate_response_unified(\n",
    "        user_input,\n",
    "        emotion=emotion,\n",
    "        affection=affection,\n",
    "        character_name=char_name,  # Optional cosmetic name\n",
    "        max_new_tokens=50,\n",
    "        temperature=0.7,\n",
    "        top_p=0.85\n",
    "    )\n",
    "\n",
    "    # Count tokens in response\n",
    "    response_tokens = len(tokenizer.encode(response))\n",
    "\n",
    "    # Display with or without name\n",
    "    display_name = f\" as '{char_name}'\" if char_name else \"\"\n",
    "    print(f\"Unified Character{display_name} (Affection: {affection}/100, Emotion: {emotion})\")\n",
    "    print(f\"User: {user_input}\")\n",
    "    print(f\"Response ({response_tokens} tokens): {response}\")\n",
    "    print(\"-\"*80)\n",
    "\n",
    "print(\"\\nâœ… Unified character testing complete\")\n",
    "print(\"   Model trained on ~439 merged examples (vs 90-128 per character)\")\n",
    "print(\"   Expected: Better coherence and quality than separate character training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EOS Token Generation Diagnostic (Unified Character)\n",
      "================================================================================\n",
      "\n",
      "Test prompt: 'Hello!'\n",
      "Input length: 166 tokens\n",
      "EOS token ID: 128009\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Generated Token Analysis:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Total tokens generated: 25\n",
      "Token IDs (first 20): [2675, 2873, 11919, 3432, 13, 2650, 596, 701, 2046, 2133, 779, 3117, 30, 42033, 7185, 3621, 477, 527, 499, 1120]\n",
      "\n",
      "âœ… EOS token (128009) found: True\n",
      "   EOS position: 24/25 tokens\n",
      "   Generated 24 tokens before EOS\n",
      "   âœ… Model learned proper stopping behavior\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Generated Text (with special tokens):\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "You seem friendly today. How's your week going so far? Anything interesting happen or are you just enjoying the moment?<|eot_id|>\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Generated Text (cleaned):\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "You seem friendly today. How's your week going so far? Anything interesting happen or are you just enjoying the moment?\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: Verify EOS token generation for unified character\n",
    "print(\"=\"*80)\n",
    "print(\"EOS Token Generation Diagnostic (Unified Character)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test with a simple prompt\n",
    "test_input = \"Hello!\"\n",
    "\n",
    "system_content = f\"\"\"{UNIFIED_PERSONA_BASE}\n",
    "\n",
    "Current affection: 50/100\n",
    "User's emotional state: neutral\n",
    "\n",
    "Respond naturally based on the conversation context.\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_content},\n",
    "    {\"role\": \"user\", \"content\": test_input}\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
    "input_length = inputs['input_ids'].shape[1]\n",
    "\n",
    "print(f\"\\nTest prompt: '{test_input}'\")\n",
    "print(f\"Input length: {input_length} tokens\")\n",
    "print(f\"EOS token ID: {tokenizer.eos_token_id}\")\n",
    "\n",
    "# Generate with return_dict to get detailed output\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=50,\n",
    "        temperature=0.7,\n",
    "        top_p=0.85,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        early_stopping=True,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True\n",
    "    )\n",
    "\n",
    "# Analyze generated tokens\n",
    "generated_ids = outputs.sequences[0][input_length:]\n",
    "generated_text = tokenizer.decode(generated_ids, skip_special_tokens=False)\n",
    "\n",
    "print(f\"\\n{'â”€'*80}\")\n",
    "print(\"Generated Token Analysis:\")\n",
    "print(f\"{'â”€'*80}\")\n",
    "print(f\"Total tokens generated: {len(generated_ids)}\")\n",
    "print(f\"Token IDs (first 20): {generated_ids.tolist()[:20]}\")\n",
    "\n",
    "# Check for EOS token\n",
    "eos_found = tokenizer.eos_token_id in generated_ids\n",
    "print(f\"\\n{'âœ…' if eos_found else 'âŒ'} EOS token ({tokenizer.eos_token_id}) found: {eos_found}\")\n",
    "\n",
    "if eos_found:\n",
    "    eos_position = (generated_ids == tokenizer.eos_token_id).nonzero()[0].item()\n",
    "    print(f\"   EOS position: {eos_position}/{len(generated_ids)} tokens\")\n",
    "    print(f\"   Generated {eos_position} tokens before EOS\")\n",
    "    print(f\"   âœ… Model learned proper stopping behavior\")\n",
    "else:\n",
    "    print(f\"   Model hit max_new_tokens limit without generating EOS\")\n",
    "    print(f\"   âš ï¸  Model needs more training to learn proper stopping\")\n",
    "\n",
    "print(f\"\\n{'â”€'*80}\")\n",
    "print(\"Generated Text (with special tokens):\")\n",
    "print(f\"{'â”€'*80}\")\n",
    "print(generated_text[:300] + \"...\" if len(generated_text) > 300 else generated_text)\n",
    "\n",
    "print(f\"\\n{'â”€'*80}\")\n",
    "print(\"Generated Text (cleaned):\")\n",
    "print(f\"{'â”€'*80}\")\n",
    "clean_text = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
    "print(clean_text)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
