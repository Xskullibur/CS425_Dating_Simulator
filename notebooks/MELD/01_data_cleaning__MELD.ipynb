{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MELD Dataset Data Cleaning for Dating Simulator\n",
    "\n",
    "This notebook processes the MELD (Multimodal EmotionLines Dataset) from YAML format into a cleaned CSV suitable for dating simulator fine-tuning with Friends character personas.\n",
    "\n",
    "**Dataset:** MELD - Friends TV show dialogue with emotion labels\n",
    "\n",
    "**Input:** `data/raw/MELD/data/MELD/datasets.yaml`\n",
    "\n",
    "**Output:** `data/processed/MELD/meld_romantic_cleaned.csv`\n",
    "\n",
    "**Processing:**\n",
    "1. Load and parse YAML structure (dev/test/train splits)\n",
    "2. Sort chronologically by Season → Episode → StartTime\n",
    "3. **Filter to romantic/dating conversations** (Monica+Chandler, Ross+Rachel, Phoebe+dates, etc.)\n",
    "4. **Filter to 1-on-1 conversations only** (exclude multi-party group scenes)\n",
    "5. Create dialogue pairs with 5-utterance context windows\n",
    "6. Include emotion labels and Friends character names\n",
    "7. Save statistics and cleaned dataset\n",
    "\n",
    "**Key Features for Dating Simulator:**\n",
    "- ✅ Romance and flirting context only\n",
    "- ✅ 1-on-1 conversations (no multi-party)\n",
    "- ✅ Friends character personas (Chandler, Monica, Ross, Rachel, Joey, Phoebe)\n",
    "- ✅ Emotion labels for emotion-conditioned training\n",
    "- ✅ NO sentiment column (not needed)\n",
    "- ✅ Speaker tokens in format `<Speaker>` for persona learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in e:\\.current\\projects\\cs425_project\\.venv\\lib\\site-packages (6.0.3)\n",
      "Requirement already satisfied: pandas in e:\\.current\\projects\\cs425_project\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in e:\\.current\\projects\\cs425_project\\.venv\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\.current\\projects\\cs425_project\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\.current\\projects\\cs425_project\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\.current\\projects\\cs425_project\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in e:\\.current\\projects\\cs425_project\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pyyaml pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MELD dataset from: ..\\..\\data\\raw\\MELD\\data\\MELD\\datasets.yaml\n",
      "Output directory: ..\\..\\data\\processed\\MELD\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "\n",
    "# Set paths\n",
    "yaml_file = Path(\"../../data/raw/MELD/data/MELD/datasets.yaml\")\n",
    "output_dir = Path(\"../../data/processed/MELD\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Loading MELD dataset from: {yaml_file}\")\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Parse YAML Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading YAML file...\n",
      "Loaded data with splits: ['dev', 'test', 'train']\n"
     ]
    }
   ],
   "source": [
    "# Load YAML file\n",
    "print(\"Loading YAML file...\")\n",
    "with open(yaml_file, 'r', encoding='utf-8') as f:\n",
    "    meld_data = yaml.safe_load(f)\n",
    "\n",
    "print(f\"Loaded data with splits: {list(meld_data.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattening YAML structure...\n",
      "Total utterances: 13707\n",
      "\n",
      "DataFrame shape: (13707, 12)\n",
      "\n",
      "Columns: ['Dialogue_ID', 'Emotion', 'EndTime', 'Episode', 'Season', 'Sentiment', 'Speaker', 'SrNo', 'StartTime', 'Utterance', 'Utterance_ID', 'split']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>EndTime</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Season</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>SrNo</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "      <td>00:21:00,049</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>1</td>\n",
       "      <td>00:20:57,256</td>\n",
       "      <td>Oh my God, he’s lost it. He’s totally lost it.</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>surprise</td>\n",
       "      <td>00:21:03,261</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>Monica</td>\n",
       "      <td>2</td>\n",
       "      <td>00:21:01,927</td>\n",
       "      <td>What?</td>\n",
       "      <td>1</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>neutral</td>\n",
       "      <td>00:13:26,460</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Monica</td>\n",
       "      <td>1064</td>\n",
       "      <td>00:13:23,916</td>\n",
       "      <td>Okay. It’s Emma.</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>sadness</td>\n",
       "      <td>00:13:35,928</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>negative</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>1065</td>\n",
       "      <td>00:13:27,795</td>\n",
       "      <td>Emma!  See? I don’t want it.</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0:13:42,477</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Monica</td>\n",
       "      <td>1066</td>\n",
       "      <td>0:13:40,766</td>\n",
       "      <td>Take it.</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dialogue_ID   Emotion       EndTime Episode Season Sentiment Speaker  SrNo  \\\n",
       "0           0   sadness  00:21:00,049       7      4  negative  Phoebe     1   \n",
       "1           0  surprise  00:21:03,261       7      4  negative  Monica     2   \n",
       "2         100   neutral  00:13:26,460       1      1   neutral  Monica  1064   \n",
       "3         101   sadness  00:13:35,928       4      8  negative  Rachel  1065   \n",
       "4         102   neutral   0:13:42,477       2      1   neutral  Monica  1066   \n",
       "\n",
       "      StartTime                                       Utterance Utterance_ID  \\\n",
       "0  00:20:57,256  Oh my God, he’s lost it. He’s totally lost it.            0   \n",
       "1  00:21:01,927                                           What?            1   \n",
       "2  00:13:23,916                                Okay. It’s Emma.            0   \n",
       "3  00:13:27,795                    Emma!  See? I don’t want it.            0   \n",
       "4   0:13:40,766                                        Take it.            0   \n",
       "\n",
       "  split  \n",
       "0   dev  \n",
       "1   dev  \n",
       "2   dev  \n",
       "3   dev  \n",
       "4   dev  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten YAML structure into list of dictionaries\n",
    "def flatten_yaml_data(yaml_dict):\n",
    "    \"\"\"\n",
    "    Convert nested YAML structure to flat list of utterance dictionaries.\n",
    "    \n",
    "    Input structure:\n",
    "    {\n",
    "        'dev': {\n",
    "            'dia0_utt0': {'Dialogue_ID': '0', 'Utterance': '...', ...},\n",
    "            'dia0_utt1': {'Dialogue_ID': '0', 'Utterance': '...', ...},\n",
    "            ...\n",
    "        },\n",
    "        'test': {...},\n",
    "        'train': {...}\n",
    "    }\n",
    "    \n",
    "    Output:\n",
    "    [\n",
    "        {'split': 'dev', 'Dialogue_ID': '0', 'Utterance_ID': '0', 'Utterance': '...', ...},\n",
    "        ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    all_utterances = []\n",
    "    \n",
    "    for split_name, split_data in yaml_dict.items():\n",
    "        for key, utterance_dict in split_data.items():\n",
    "            # Add split name to track which split this came from\n",
    "            utterance_dict['split'] = split_name\n",
    "            all_utterances.append(utterance_dict)\n",
    "    \n",
    "    return all_utterances\n",
    "\n",
    "print(\"Flattening YAML structure...\")\n",
    "utterances = flatten_yaml_data(meld_data)\n",
    "print(f\"Total utterances: {len(utterances)}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(utterances)\n",
    "print(f\"\\nDataFrame shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13707 entries, 0 to 13706\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Dialogue_ID   13707 non-null  object\n",
      " 1   Emotion       13707 non-null  object\n",
      " 2   EndTime       13707 non-null  object\n",
      " 3   Episode       13707 non-null  object\n",
      " 4   Season        13707 non-null  object\n",
      " 5   Sentiment     13707 non-null  object\n",
      " 6   Speaker       13707 non-null  object\n",
      " 7   SrNo          13707 non-null  object\n",
      " 8   StartTime     13707 non-null  object\n",
      " 9   Utterance     13707 non-null  object\n",
      " 10  Utterance_ID  13707 non-null  object\n",
      " 11  split         13707 non-null  object\n",
      "dtypes: object(12)\n",
      "memory usage: 1.3+ MB\n",
      "None\n",
      "\n",
      "Emotion distribution:\n",
      "Emotion\n",
      "neutral     6435\n",
      "joy         2308\n",
      "surprise    1636\n",
      "anger       1607\n",
      "sadness     1002\n",
      "disgust      361\n",
      "fear         358\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sentiment distribution:\n",
      "Sentiment\n",
      "neutral     6435\n",
      "negative    4184\n",
      "positive    3088\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Split distribution:\n",
      "split\n",
      "train    9989\n",
      "test     2610\n",
      "dev      1108\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check data types and basic statistics\n",
    "print(\"Data info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nEmotion distribution:\")\n",
    "print(df['Emotion'].value_counts())\n",
    "\n",
    "print(\"\\nSentiment distribution:\")\n",
    "print(df['Sentiment'].value_counts())\n",
    "\n",
    "print(\"\\nSplit distribution:\")\n",
    "print(df['split'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normalize Timestamps and Sort Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing timestamp parser:\n",
      "00:21:00,049 -> 1260.049 seconds\n",
      "0:13:42,477 -> 822.477 seconds\n",
      "00:00:05,123 -> 5.123 seconds\n"
     ]
    }
   ],
   "source": [
    "def parse_timestamp(timestamp_str):\n",
    "    \"\"\"\n",
    "    Parse timestamp string to total seconds.\n",
    "    Handles formats: \"HH:MM:SS,milliseconds\" and \"H:MM:SS,milliseconds\"\n",
    "    \n",
    "    Example: \"00:21:00,049\" or \"0:13:42,477\" -> total seconds as float\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Replace comma with period for milliseconds\n",
    "        timestamp_str = timestamp_str.replace(',', '.')\n",
    "        \n",
    "        # Split into time and milliseconds\n",
    "        parts = timestamp_str.split('.')\n",
    "        time_part = parts[0]\n",
    "        milliseconds = int(parts[1]) if len(parts) > 1 else 0\n",
    "        \n",
    "        # Parse time part\n",
    "        time_components = time_part.split(':')\n",
    "        hours = int(time_components[0])\n",
    "        minutes = int(time_components[1])\n",
    "        seconds = int(time_components[2])\n",
    "        \n",
    "        # Convert to total seconds\n",
    "        total_seconds = hours * 3600 + minutes * 60 + seconds + milliseconds / 1000.0\n",
    "        \n",
    "        return total_seconds\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing timestamp '{timestamp_str}': {e}\")\n",
    "        return 0.0\n",
    "\n",
    "# Test timestamp parser\n",
    "print(\"Testing timestamp parser:\")\n",
    "test_timestamps = [\"00:21:00,049\", \"0:13:42,477\", \"00:00:05,123\"]\n",
    "for ts in test_timestamps:\n",
    "    print(f\"{ts} -> {parse_timestamp(ts)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing timestamps...\n",
      "\n",
      "Sample with parsed timestamps:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>StartTime_seconds</th>\n",
       "      <th>Utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>00:20:57,256</td>\n",
       "      <td>1257.256</td>\n",
       "      <td>Oh my God, he’s lost it. He’s totally lost it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>00:21:01,927</td>\n",
       "      <td>1261.927</td>\n",
       "      <td>What?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>00:13:23,916</td>\n",
       "      <td>803.916</td>\n",
       "      <td>Okay. It’s Emma.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>00:13:27,795</td>\n",
       "      <td>807.795</td>\n",
       "      <td>Emma!  See? I don’t want it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0:13:40,766</td>\n",
       "      <td>820.766</td>\n",
       "      <td>Take it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>0:13:42,477</td>\n",
       "      <td>822.477</td>\n",
       "      <td>What?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>00:13:44,395</td>\n",
       "      <td>824.395</td>\n",
       "      <td>It’s clearly an Emma.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>00:13:46,605</td>\n",
       "      <td>826.605</td>\n",
       "      <td>Oh honey, but you love that name.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>00:13:49,817</td>\n",
       "      <td>829.817</td>\n",
       "      <td>Yeah, but I love you more.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>0:13:55,072</td>\n",
       "      <td>835.072</td>\n",
       "      <td>Besides y’know, nothing goes with Bing.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Season Episode Dialogue_ID Utterance_ID     StartTime  StartTime_seconds  \\\n",
       "0      4       7           0            0  00:20:57,256           1257.256   \n",
       "1      4       7           0            1  00:21:01,927           1261.927   \n",
       "2      1       1         100            0  00:13:23,916            803.916   \n",
       "3      8       4         101            0  00:13:27,795            807.795   \n",
       "4      1       2         102            0   0:13:40,766            820.766   \n",
       "5      1       2         102            1   0:13:42,477            822.477   \n",
       "6      8      24         103            0  00:13:44,395            824.395   \n",
       "7      8      24         103            1  00:13:46,605            826.605   \n",
       "8      8      24         103            2  00:13:49,817            829.817   \n",
       "9      8      24         103            3   0:13:55,072            835.072   \n",
       "\n",
       "                                        Utterance  \n",
       "0  Oh my God, he’s lost it. He’s totally lost it.  \n",
       "1                                           What?  \n",
       "2                                Okay. It’s Emma.  \n",
       "3                    Emma!  See? I don’t want it.  \n",
       "4                                        Take it.  \n",
       "5                                           What?  \n",
       "6                           It’s clearly an Emma.  \n",
       "7               Oh honey, but you love that name.  \n",
       "8                      Yeah, but I love you more.  \n",
       "9         Besides y’know, nothing goes with Bing.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add parsed timestamp columns\n",
    "print(\"Parsing timestamps...\")\n",
    "df['StartTime_seconds'] = df['StartTime'].apply(parse_timestamp)\n",
    "df['EndTime_seconds'] = df['EndTime'].apply(parse_timestamp)\n",
    "\n",
    "# Convert string columns to integers for sorting\n",
    "df['Season_int'] = df['Season'].astype(int)\n",
    "df['Episode_int'] = df['Episode'].astype(int)\n",
    "df['Dialogue_ID_int'] = df['Dialogue_ID'].astype(int)\n",
    "df['Utterance_ID_int'] = df['Utterance_ID'].astype(int)\n",
    "df['SrNo_int'] = df['SrNo'].astype(int)\n",
    "\n",
    "print(\"\\nSample with parsed timestamps:\")\n",
    "df[['Season', 'Episode', 'Dialogue_ID', 'Utterance_ID', 'StartTime', 'StartTime_seconds', 'Utterance']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting data chronologically...\n",
      "Sorted 13707 utterances\n",
      "\n",
      "Verifying sorting - first dialogue:\n",
      "  Dialogue_ID Utterance_ID   Speaker     StartTime                                                                                                            Utterance\n",
      "0         559            0  Chandler  00:01:19,037  Alright, so I'm back in high school, I'm standing in the middle of the cafeteria, and I realize I am totally naked.\n",
      "1         559            1       All  00:01:25,627                                                                                            Oh, yeah. Had that dream.\n",
      "2         559            2  Chandler  00:01:27,378                                                            Then I look down, and I realize there's a phone... there.\n",
      "3         559            3      Joey   0:01:34,928                                                                                                       Instead of...?\n",
      "4         559            4  Chandler   0:01:35,600                                                                                                        That's right.\n",
      "5         559            5      Joey   0:01:37,055                                                                                                Never had that dream.\n",
      "6         559            6    Phoebe   0:01:37,973                                                                                                                  No.\n",
      "7         559            7  Chandler  00:01:38,723                                                                           All of a sudden, the phone starts to ring.\n"
     ]
    }
   ],
   "source": [
    "# Sort data chronologically\n",
    "print(\"Sorting data chronologically...\")\n",
    "df_sorted = df.sort_values(\n",
    "    by=['Season_int', 'Episode_int', 'StartTime_seconds', 'Dialogue_ID_int', 'Utterance_ID_int'],\n",
    "    ascending=True\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(f\"Sorted {len(df_sorted)} utterances\")\n",
    "\n",
    "# Verify sorting by checking a few dialogues\n",
    "print(\"\\nVerifying sorting - first dialogue:\")\n",
    "first_dialogue = df_sorted[df_sorted['Dialogue_ID_int'] == df_sorted['Dialogue_ID_int'].iloc[0]]\n",
    "print(first_dialogue[['Dialogue_ID', 'Utterance_ID', 'Speaker', 'StartTime', 'Utterance']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Filter to Romance/Flirting Conversations and 1-on-1 Only\n",
    "\n",
    "For dating simulator, we need:\n",
    "1. **Romance + flirting context**: Conversations between romantic couples or involving dating/flirting\n",
    "2. **1-on-1 conversations only**: Exclude multi-party group conversations (3+ speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering dialogues...\n",
      "Total dialogues before filtering: 1039\n",
      "Found 181 romantic/dating dialogues with exactly 2 speakers\n",
      "Total utterances after filtering: 1710 (from 13707)\n"
     ]
    }
   ],
   "source": [
    "# Define romantic relationships in Friends\n",
    "ROMANTIC_PAIRS = [\n",
    "    ('Monica', 'Chandler'),  # Main couple\n",
    "    ('Ross', 'Rachel'),      # On-again/off-again couple\n",
    "    ('Phoebe', 'Mike'),      # Later seasons couple\n",
    "    ('Phoebe', 'David'),     # Phoebe's scientist boyfriend\n",
    "]\n",
    "\n",
    "# Characters known for dating/flirting scenes\n",
    "DATING_CHARACTERS = ['Joey', 'Chandler', 'Ross', 'Rachel', 'Monica', 'Phoebe']\n",
    "\n",
    "def is_romantic_dialogue(dialogue_df):\n",
    "    \"\"\"\n",
    "    Check if a dialogue involves romance/flirting.\n",
    "    \n",
    "    Returns True if:\n",
    "    - Dialogue is between a known romantic couple\n",
    "    - Dialogue involves dating-related emotions between main characters\n",
    "    \"\"\"\n",
    "    speakers = set(dialogue_df['Speaker'].unique())\n",
    "    \n",
    "    # Check if dialogue is between a romantic pair\n",
    "    for person1, person2 in ROMANTIC_PAIRS:\n",
    "        if speakers == {person1, person2}:\n",
    "            return True\n",
    "    \n",
    "    # Check for dating/flirting indicators\n",
    "    # If dialogue is between 2 main characters and includes joy/surprise/sadness (dating emotions)\n",
    "    if len(speakers) == 2:\n",
    "        if speakers.issubset(set(DATING_CHARACTERS)):\n",
    "            emotions = dialogue_df['Emotion'].values\n",
    "            # Romance often involves joy, surprise, nervousness (modeled as fear), or sadness\n",
    "            romance_emotions = {'joy', 'surprise', 'fear', 'sadness'}\n",
    "            if any(emo in romance_emotions for emo in emotions):\n",
    "                # Additional filter: avoid purely platonic exchanges (e.g., work conversations)\n",
    "                # Check if there's emotional variety (not all neutral)\n",
    "                if 'joy' in emotions or 'surprise' in emotions:\n",
    "                    return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "print(\"Filtering dialogues...\")\n",
    "print(f\"Total dialogues before filtering: {df_sorted['Dialogue_ID_int'].nunique()}\")\n",
    "\n",
    "# Group by dialogue and filter\n",
    "romantic_dialogue_ids = []\n",
    "for dialogue_id, dialogue_df in df_sorted.groupby('Dialogue_ID_int'):\n",
    "    # Check 1: Must be 1-on-1 (exactly 2 speakers)\n",
    "    unique_speakers = dialogue_df['Speaker'].nunique()\n",
    "    if unique_speakers != 2:\n",
    "        continue\n",
    "    \n",
    "    # Check 2: Must be romantic/flirting context\n",
    "    if is_romantic_dialogue(dialogue_df):\n",
    "        romantic_dialogue_ids.append(dialogue_id)\n",
    "\n",
    "print(f\"Found {len(romantic_dialogue_ids)} romantic/dating dialogues with exactly 2 speakers\")\n",
    "\n",
    "# Filter dataset to only romantic 1-on-1 dialogues\n",
    "df_romantic = df_sorted[df_sorted['Dialogue_ID_int'].isin(romantic_dialogue_ids)].reset_index(drop=True)\n",
    "print(f\"Total utterances after filtering: {len(df_romantic)} (from {len(df_sorted)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Romantic/Dating Dialogue Analysis\n",
      "================================================================================\n",
      "\n",
      "Speaker pair distribution:\n",
      "  Chandler + Monica: 29 dialogues\n",
      "  Rachel + Ross: 23 dialogues\n",
      "  Chandler + Joey: 22 dialogues\n",
      "  Phoebe + Rachel: 14 dialogues\n",
      "  Joey + Phoebe: 13 dialogues\n",
      "  Monica + Rachel: 13 dialogues\n",
      "  Joey + Ross: 11 dialogues\n",
      "  Monica + Phoebe: 10 dialogues\n",
      "  Joey + Monica: 9 dialogues\n",
      "  Joey + Rachel: 9 dialogues\n",
      "  Phoebe + Ross: 8 dialogues\n",
      "  Chandler + Phoebe: 5 dialogues\n",
      "  Chandler + Rachel: 5 dialogues\n",
      "  Chandler + Ross: 4 dialogues\n",
      "  Monica + Ross: 4 dialogues\n",
      "  David + Phoebe: 1 dialogues\n",
      "  Mike + Phoebe: 1 dialogues\n",
      "\n",
      "Emotion distribution in romantic dialogues:\n",
      "  neutral        :   752 (43.98%)\n",
      "  joy            :   297 (17.37%)\n",
      "  anger          :   220 (12.87%)\n",
      "  surprise       :   216 (12.63%)\n",
      "  sadness        :   151 ( 8.83%)\n",
      "  fear           :    41 ( 2.40%)\n",
      "  disgust        :    33 ( 1.93%)\n",
      "\n",
      "================================================================================\n",
      "Sample Romantic Dialogue\n",
      "================================================================================\n",
      "Dialogue ID: 134\n",
      "Speakers: Chandler, Ross\n",
      "Season 1, Episode 4\n",
      "\n",
      "Conversation:\n",
      "  Chandler (neutral): Hello?\n",
      "  Ross (surprise): What happened?\n",
      "  Chandler (sadness): He’s not gonna make it, he’s stuck in Chicago.\n",
      "  Ross (joy): Ohh, man! Chicago, is sooo lucky!\n",
      "  Chandler (anger): Stupid, useless Canadian money!\n"
     ]
    }
   ],
   "source": [
    "# Analyze filtered romantic dialogues\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Romantic/Dating Dialogue Analysis\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nSpeaker pair distribution:\")\n",
    "speaker_pairs = {}\n",
    "for dialogue_id in romantic_dialogue_ids:\n",
    "    dialogue_df = df_sorted[df_sorted['Dialogue_ID_int'] == dialogue_id]\n",
    "    speakers = tuple(sorted(dialogue_df['Speaker'].unique()))\n",
    "    speaker_pairs[speakers] = speaker_pairs.get(speakers, 0) + 1\n",
    "\n",
    "for pair, count in sorted(speaker_pairs.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {pair[0]} + {pair[1]}: {count} dialogues\")\n",
    "\n",
    "print(\"\\nEmotion distribution in romantic dialogues:\")\n",
    "romantic_emotions = df_romantic['Emotion'].value_counts()\n",
    "for emotion, count in romantic_emotions.items():\n",
    "    percentage = (count / len(df_romantic)) * 100\n",
    "    print(f\"  {emotion:15s}: {count:5d} ({percentage:5.2f}%)\")\n",
    "\n",
    "# Show sample romantic dialogue\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Sample Romantic Dialogue\")\n",
    "print(\"=\"*80)\n",
    "sample_dialogue_id = romantic_dialogue_ids[0] if romantic_dialogue_ids else None\n",
    "if sample_dialogue_id:\n",
    "    sample_dialogue = df_romantic[df_romantic['Dialogue_ID_int'] == sample_dialogue_id]\n",
    "    print(f\"Dialogue ID: {sample_dialogue_id}\")\n",
    "    print(f\"Speakers: {', '.join(sample_dialogue['Speaker'].unique())}\")\n",
    "    print(f\"Season {sample_dialogue['Season'].iloc[0]}, Episode {sample_dialogue['Episode'].iloc[0]}\")\n",
    "    print(\"\\nConversation:\")\n",
    "    for _, row in sample_dialogue.iterrows():\n",
    "        print(f\"  {row['Speaker']} ({row['Emotion']}): {row['Utterance']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dialogue pairs with window_size=5...\n",
      "Created 1529 dialogue pairs from romantic 1-on-1 conversations\n"
     ]
    }
   ],
   "source": [
    "def create_dialogue_pairs_with_boundaries(df, window_size=5):\n",
    "    \"\"\"\n",
    "    Create dialogue pairs for 1-on-1 romantic conversations.\n",
    "    \n",
    "    For each utterance (response):\n",
    "    - Context: Previous `window_size` utterances FROM THE SAME DIALOGUE WITH SPEAKER TOKENS\n",
    "    - Response: Current utterance\n",
    "    - Emotion: Emotion label of the response\n",
    "    - Character: Who is speaking (Friends character name)\n",
    "    \n",
    "    Speaker tokens are included in the format: <Speaker> utterance text\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with sorted utterances (already filtered to romantic 1-on-1)\n",
    "        window_size: Number of previous utterances to use as context\n",
    "    \n",
    "    Returns:\n",
    "        List of dialogue pair dictionaries\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    \n",
    "    # Group by dialogue\n",
    "    grouped = df.groupby('Dialogue_ID_int')\n",
    "    \n",
    "    for dialogue_id, dialogue_df in grouped:\n",
    "        dialogue_df = dialogue_df.sort_values('Utterance_ID_int').reset_index(drop=True)\n",
    "        utterances = dialogue_df['Utterance'].tolist()\n",
    "        emotions = dialogue_df['Emotion'].tolist()\n",
    "        speakers = dialogue_df['Speaker'].tolist()\n",
    "        seasons = dialogue_df['Season'].tolist()\n",
    "        episodes = dialogue_df['Episode'].tolist()\n",
    "        \n",
    "        # Create pairs within this dialogue\n",
    "        for i in range(len(utterances)):\n",
    "            # Determine context range\n",
    "            if i < window_size:\n",
    "                # Use all available context (partial window for early utterances)\n",
    "                context_start = 0\n",
    "                context_end = i\n",
    "            else:\n",
    "                # Full window\n",
    "                context_start = i - window_size\n",
    "                context_end = i\n",
    "            \n",
    "            # Skip if no context (first utterance of dialogue)\n",
    "            if context_start == context_end:\n",
    "                continue\n",
    "            \n",
    "            # Get context utterances WITH speaker tokens\n",
    "            context_parts = []\n",
    "            for j in range(context_start, context_end):\n",
    "                speaker = speakers[j]\n",
    "                utterance = utterances[j]\n",
    "                context_parts.append(f\"<{speaker}> {utterance}\")\n",
    "            context = ' '.join(context_parts)\n",
    "            \n",
    "            # Create pair\n",
    "            pair = {\n",
    "                'character': speakers[i],  # Friends character name\n",
    "                'emotion': emotions[i],\n",
    "                'context': context,\n",
    "                'response': utterances[i],\n",
    "                'dialogue_id': str(dialogue_id),\n",
    "                'season': seasons[i],\n",
    "                'episode': episodes[i]\n",
    "            }\n",
    "            pairs.append(pair)\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "print(f\"Creating dialogue pairs with window_size=5...\")\n",
    "dialogue_pairs = create_dialogue_pairs_with_boundaries(df_romantic, window_size=5)\n",
    "print(f\"Created {len(dialogue_pairs)} dialogue pairs from romantic 1-on-1 conversations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue pairs DataFrame shape: (1529, 7)\n",
      "\n",
      "Columns: ['character', 'emotion', 'context', 'response', 'dialogue_id', 'season', 'episode']\n",
      "\n",
      "================================================================================\n",
      "Sample Romantic Dialogue Pairs (1-on-1, with speaker tokens)\n",
      "================================================================================\n",
      "\n",
      "--- Pair 1 ---\n",
      "Character: Ross\n",
      "Emotion: surprise\n",
      "Context:\n",
      "  <Chandler> Hello?\n",
      "Response:\n",
      "  What happened?\n",
      "Metadata: Season 4, Episode 9, Dialogue 134\n",
      "\n",
      "--- Pair 2 ---\n",
      "Character: Chandler\n",
      "Emotion: sadness\n",
      "Context:\n",
      "  <Chandler> Hello? <Ross> What happened?\n",
      "Response:\n",
      "  He’s not gonna make it, he’s stuck in Chicago.\n",
      "Metadata: Season 4, Episode 9, Dialogue 134\n",
      "\n",
      "--- Pair 3 ---\n",
      "Character: Ross\n",
      "Emotion: joy\n",
      "Context:\n",
      "  <Chandler> Hello? <Ross> What happened? <Chandler> He’s not gonna make it, he’s stuck in Chicago.\n",
      "Response:\n",
      "  Ohh, man! Chicago, is sooo lucky!\n",
      "Metadata: Season 4, Episode 9, Dialogue 134\n",
      "\n",
      "--- Pair 4 ---\n",
      "Character: Chandler\n",
      "Emotion: anger\n",
      "Context:\n",
      "  <Chandler> Hello? <Ross> What happened? <Chandler> He’s not gonna make it, he’s stuck in Chicago. <Ross> Ohh, man! Chicago, is sooo lucky!\n",
      "Response:\n",
      "  Stupid, useless Canadian money!\n",
      "Metadata: Season 4, Episode 9, Dialogue 134\n",
      "\n",
      "--- Pair 5 ---\n",
      "Character: Ross\n",
      "Emotion: neutral\n",
      "Context:\n",
      "  <Joey> I don’t get it!\n",
      "Response:\n",
      "  Hey! So uh, was he excited about the tickets?\n",
      "Metadata: Season 6, Episode 23, Dialogue 200\n",
      "\n",
      "================================================================================\n",
      "Character Distribution\n",
      "================================================================================\n",
      "  Joey           :   308 (20.14%)\n",
      "  Rachel         :   280 (18.31%)\n",
      "  Monica         :   261 (17.07%)\n",
      "  Chandler       :   241 (15.76%)\n",
      "  Phoebe         :   231 (15.11%)\n",
      "  Ross           :   199 (13.02%)\n",
      "  Mike           :     7 ( 0.46%)\n",
      "  David          :     2 ( 0.13%)\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "pairs_df = pd.DataFrame(dialogue_pairs)\n",
    "\n",
    "print(f\"Dialogue pairs DataFrame shape: {pairs_df.shape}\")\n",
    "print(f\"\\nColumns: {list(pairs_df.columns)}\")\n",
    "\n",
    "# Display sample pairs\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Sample Romantic Dialogue Pairs (1-on-1, with speaker tokens)\")\n",
    "print(\"=\"*80)\n",
    "for i in range(min(5, len(pairs_df))):\n",
    "    pair = pairs_df.iloc[i]\n",
    "    print(f\"\\n--- Pair {i+1} ---\")\n",
    "    print(f\"Character: {pair['character']}\")\n",
    "    print(f\"Emotion: {pair['emotion']}\")\n",
    "    print(f\"Context:\")\n",
    "    context_display = pair['context'][:200] + \"...\" if len(pair['context']) > 200 else pair['context']\n",
    "    print(f\"  {context_display}\")\n",
    "    print(f\"Response:\")\n",
    "    response_display = pair['response'][:150] + \"...\" if len(pair['response']) > 150 else pair['response']\n",
    "    print(f\"  {response_display}\")\n",
    "    print(f\"Metadata: Season {pair['season']}, Episode {pair['episode']}, Dialogue {pair['dialogue_id']}\")\n",
    "\n",
    "# Show character distribution\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Character Distribution\")\n",
    "print(\"=\"*80)\n",
    "character_counts = pairs_df['character'].value_counts()\n",
    "for character, count in character_counts.items():\n",
    "    percentage = (count / len(pairs_df)) * 100\n",
    "    print(f\"  {character:15s}: {count:5d} ({percentage:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Dialogue Pairs with Context Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Final Dataset Statistics (Romantic 1-on-1 Conversations Only)\n",
      "================================================================================\n",
      "\n",
      "Total utterances in raw MELD data: 13707\n",
      "Total utterances after romantic 1-on-1 filtering: 1710\n",
      "Total dialogue pairs created: 1529\n",
      "Total unique dialogues: 181\n",
      "Total unique characters: 8\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Character Distribution:\n",
      "--------------------------------------------------------------------------------\n",
      "Joey           :   308 (20.14%)\n",
      "Rachel         :   280 (18.31%)\n",
      "Monica         :   261 (17.07%)\n",
      "Chandler       :   241 (15.76%)\n",
      "Phoebe         :   231 (15.11%)\n",
      "Ross           :   199 (13.02%)\n",
      "Mike           :     7 ( 0.46%)\n",
      "David          :     2 ( 0.13%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Emotion Distribution:\n",
      "--------------------------------------------------------------------------------\n",
      "neutral        :   676 (44.21%)\n",
      "joy            :   248 (16.22%)\n",
      "anger          :   202 (13.21%)\n",
      "surprise       :   193 (12.62%)\n",
      "sadness        :   141 ( 9.22%)\n",
      "fear           :    38 ( 2.49%)\n",
      "disgust        :    31 ( 2.03%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Length Statistics:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Context length (words):\n",
      "  Mean: 34.75\n",
      "  Median: 34.00\n",
      "  Min: 2\n",
      "  Max: 103\n",
      "\n",
      "Response length (words):\n",
      "  Mean: 7.97\n",
      "  Median: 6.00\n",
      "  Min: 1\n",
      "  Max: 44\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Dialogue Statistics:\n",
      "--------------------------------------------------------------------------------\n",
      "Average utterances per dialogue: 9.45\n",
      "Median utterances per dialogue: 8.00\n",
      "Min utterances per dialogue: 2\n",
      "Max utterances per dialogue: 24\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Final Dataset Statistics (Romantic 1-on-1 Conversations Only)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nTotal utterances in raw MELD data: {len(df)}\")\n",
    "print(f\"Total utterances after romantic 1-on-1 filtering: {len(df_romantic)}\")\n",
    "print(f\"Total dialogue pairs created: {len(pairs_df)}\")\n",
    "print(f\"Total unique dialogues: {len(romantic_dialogue_ids)}\")\n",
    "print(f\"Total unique characters: {df_romantic['Speaker'].nunique()}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Character Distribution:\")\n",
    "print(\"-\"*80)\n",
    "for character, count in character_counts.items():\n",
    "    percentage = (count / len(pairs_df)) * 100\n",
    "    print(f\"{character:15s}: {count:5d} ({percentage:5.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Emotion Distribution:\")\n",
    "print(\"-\"*80)\n",
    "emotion_counts = pairs_df['emotion'].value_counts()\n",
    "for emotion, count in emotion_counts.items():\n",
    "    percentage = (count / len(pairs_df)) * 100\n",
    "    print(f\"{emotion:15s}: {count:5d} ({percentage:5.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Length Statistics:\")\n",
    "print(\"-\"*80)\n",
    "pairs_df['context_length'] = pairs_df['context'].apply(lambda x: len(x.split()))\n",
    "pairs_df['response_length'] = pairs_df['response'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print(f\"\\nContext length (words):\")\n",
    "print(f\"  Mean: {pairs_df['context_length'].mean():.2f}\")\n",
    "print(f\"  Median: {pairs_df['context_length'].median():.2f}\")\n",
    "print(f\"  Min: {pairs_df['context_length'].min()}\")\n",
    "print(f\"  Max: {pairs_df['context_length'].max()}\")\n",
    "\n",
    "print(f\"\\nResponse length (words):\")\n",
    "print(f\"  Mean: {pairs_df['response_length'].mean():.2f}\")\n",
    "print(f\"  Median: {pairs_df['response_length'].median():.2f}\")\n",
    "print(f\"  Min: {pairs_df['response_length'].min()}\")\n",
    "print(f\"  Max: {pairs_df['response_length'].max()}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Dialogue Statistics:\")\n",
    "print(\"-\"*80)\n",
    "dialogue_lengths = df_romantic.groupby('Dialogue_ID_int').size()\n",
    "print(f\"Average utterances per dialogue: {dialogue_lengths.mean():.2f}\")\n",
    "print(f\"Median utterances per dialogue: {dialogue_lengths.median():.2f}\")\n",
    "print(f\"Min utterances per dialogue: {dialogue_lengths.min()}\")\n",
    "print(f\"Max utterances per dialogue: {dialogue_lengths.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue pairs DataFrame shape: (1529, 7)\n",
      "\n",
      "Columns: ['character', 'emotion', 'context', 'response', 'dialogue_id', 'season', 'episode']\n",
      "\n",
      "================================================================================\n",
      "Sample Dialogue Pairs (with speaker tokens in context)\n",
      "================================================================================\n",
      "\n",
      "--- Pair 1 ---\n",
      "Emotion: surprise\n",
      "Speaker (responding): Ross\n",
      "Context (with speakers):\n",
      "  <Chandler> Hello?\n",
      "Response:\n",
      "  What happened?\n",
      "Metadata: Season 4, Episode 9, Dialogue 134\n",
      "\n",
      "--- Pair 2 ---\n",
      "Emotion: sadness\n",
      "Speaker (responding): Chandler\n",
      "Context (with speakers):\n",
      "  <Chandler> Hello? <Ross> What happened?\n",
      "Response:\n",
      "  He’s not gonna make it, he’s stuck in Chicago.\n",
      "Metadata: Season 4, Episode 9, Dialogue 134\n",
      "\n",
      "--- Pair 3 ---\n",
      "Emotion: joy\n",
      "Speaker (responding): Ross\n",
      "Context (with speakers):\n",
      "  <Chandler> Hello? <Ross> What happened? <Chandler> He’s not gonna make it, he’s stuck in Chicago.\n",
      "Response:\n",
      "  Ohh, man! Chicago, is sooo lucky!\n",
      "Metadata: Season 4, Episode 9, Dialogue 134\n",
      "\n",
      "================================================================================\n",
      "Detailed Example (showing speaker attribution in context)\n",
      "================================================================================\n",
      "Emotion: surprise\n",
      "Speaker (who responds): Joey\n",
      "\n",
      "Context (notice <speaker> tokens):\n",
      "<Joey> No! He blew us off! <Joey> It was in my room all night! <Ross> What?! <Joey> And if she didn’t take it, and I didn’t take it; and you  didn’t take it, then who did? <Joey> Shh!\n",
      "\n",
      "Response (what Joey says):\n",
      "I know!\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "pairs_df = pd.DataFrame(dialogue_pairs)\n",
    "\n",
    "print(f\"Dialogue pairs DataFrame shape: {pairs_df.shape}\")\n",
    "print(f\"\\nColumns: {list(pairs_df.columns)}\")\n",
    "\n",
    "# Display sample pairs with speaker attribution\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Sample Dialogue Pairs (with speaker tokens in context)\")\n",
    "print(\"=\"*80)\n",
    "for i in range(min(3, len(pairs_df))):\n",
    "    pair = pairs_df.iloc[i]\n",
    "    print(f\"\\n--- Pair {i+1} ---\")\n",
    "    print(f\"Emotion: {pair['emotion']}\")\n",
    "    print(f\"Speaker (responding): {pair['character']}\")\n",
    "    print(f\"Context (with speakers):\")\n",
    "    # Show full context to demonstrate speaker tokens, but limit to 300 chars\n",
    "    context_display = pair['context'][:300] + \"...\" if len(pair['context']) > 300 else pair['context']\n",
    "    print(f\"  {context_display}\")\n",
    "    print(f\"Response:\")\n",
    "    response_display = pair['response'][:150] + \"...\" if len(pair['response']) > 150 else pair['response']\n",
    "    print(f\"  {response_display}\")\n",
    "    print(f\"Metadata: Season {pair['season']}, Episode {pair['episode']}, Dialogue {pair['dialogue_id']}\")\n",
    "\n",
    "# Show one example with even more detail to clearly see speaker attribution\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Detailed Example (showing speaker attribution in context)\")\n",
    "print(\"=\"*80)\n",
    "if len(pairs_df) > 0:\n",
    "    example = pairs_df.iloc[10] if len(pairs_df) > 10 else pairs_df.iloc[0]\n",
    "    print(f\"Emotion: {example['emotion']}\")\n",
    "    print(f\"Speaker (who responds): {example['character']}\")\n",
    "    print(f\"\\nContext (notice <speaker> tokens):\")\n",
    "    print(f\"{example['context']}\")\n",
    "    print(f\"\\nResponse (what {example['character']} says):\")\n",
    "    print(f\"{example['response']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved to: ..\\..\\data\\processed\\MELD\\meld_romantic_cleaned.csv\n",
      "Total rows: 1529\n",
      "\n",
      "Columns in output file: ['character', 'emotion', 'context', 'response', 'dialogue_id', 'season', 'episode']\n",
      "\n",
      "Final dataset sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>emotion</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>dialogue_id</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ross</td>\n",
       "      <td>surprise</td>\n",
       "      <td>&lt;Chandler&gt; Hello?</td>\n",
       "      <td>What happened?</td>\n",
       "      <td>134</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chandler</td>\n",
       "      <td>sadness</td>\n",
       "      <td>&lt;Chandler&gt; Hello? &lt;Ross&gt; What happened?</td>\n",
       "      <td>He’s not gonna make it, he’s stuck in Chicago.</td>\n",
       "      <td>134</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ross</td>\n",
       "      <td>joy</td>\n",
       "      <td>&lt;Chandler&gt; Hello? &lt;Ross&gt; What happened? &lt;Chand...</td>\n",
       "      <td>Ohh, man! Chicago, is sooo lucky!</td>\n",
       "      <td>134</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chandler</td>\n",
       "      <td>anger</td>\n",
       "      <td>&lt;Chandler&gt; Hello? &lt;Ross&gt; What happened? &lt;Chand...</td>\n",
       "      <td>Stupid, useless Canadian money!</td>\n",
       "      <td>134</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ross</td>\n",
       "      <td>neutral</td>\n",
       "      <td>&lt;Joey&gt; I don’t get it!</td>\n",
       "      <td>Hey! So uh, was he excited about the tickets?</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Joey</td>\n",
       "      <td>anger</td>\n",
       "      <td>&lt;Joey&gt; I don’t get it! &lt;Ross&gt; Hey! So uh, was ...</td>\n",
       "      <td>No! He blew us off!</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Joey</td>\n",
       "      <td>anger</td>\n",
       "      <td>&lt;Joey&gt; I don’t get it! &lt;Ross&gt; Hey! So uh, was ...</td>\n",
       "      <td>It was in my room all night!</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ross</td>\n",
       "      <td>surprise</td>\n",
       "      <td>&lt;Joey&gt; I don’t get it! &lt;Ross&gt; Hey! So uh, was ...</td>\n",
       "      <td>What?!</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Joey</td>\n",
       "      <td>anger</td>\n",
       "      <td>&lt;Joey&gt; I don’t get it! &lt;Ross&gt; Hey! So uh, was ...</td>\n",
       "      <td>And if she didn’t take it, and I didn’t take i...</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Joey</td>\n",
       "      <td>anger</td>\n",
       "      <td>&lt;Ross&gt; Hey! So uh, was he excited about the ti...</td>\n",
       "      <td>Shh!</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character   emotion                                            context  \\\n",
       "0      Ross  surprise                                  <Chandler> Hello?   \n",
       "1  Chandler   sadness            <Chandler> Hello? <Ross> What happened?   \n",
       "2      Ross       joy  <Chandler> Hello? <Ross> What happened? <Chand...   \n",
       "3  Chandler     anger  <Chandler> Hello? <Ross> What happened? <Chand...   \n",
       "4      Ross   neutral                             <Joey> I don’t get it!   \n",
       "5      Joey     anger  <Joey> I don’t get it! <Ross> Hey! So uh, was ...   \n",
       "6      Joey     anger  <Joey> I don’t get it! <Ross> Hey! So uh, was ...   \n",
       "7      Ross  surprise  <Joey> I don’t get it! <Ross> Hey! So uh, was ...   \n",
       "8      Joey     anger  <Joey> I don’t get it! <Ross> Hey! So uh, was ...   \n",
       "9      Joey     anger  <Ross> Hey! So uh, was he excited about the ti...   \n",
       "\n",
       "                                            response dialogue_id season  \\\n",
       "0                                     What happened?         134      4   \n",
       "1     He’s not gonna make it, he’s stuck in Chicago.         134      4   \n",
       "2                  Ohh, man! Chicago, is sooo lucky!         134      4   \n",
       "3                    Stupid, useless Canadian money!         134      4   \n",
       "4      Hey! So uh, was he excited about the tickets?         200      6   \n",
       "5                                No! He blew us off!         200      6   \n",
       "6                       It was in my room all night!         200      4   \n",
       "7                                             What?!         200      6   \n",
       "8  And if she didn’t take it, and I didn’t take i...         200      4   \n",
       "9                                               Shh!         200      4   \n",
       "\n",
       "  episode  \n",
       "0       9  \n",
       "1       9  \n",
       "2       9  \n",
       "3       9  \n",
       "4      23  \n",
       "5      23  \n",
       "6      22  \n",
       "7      23  \n",
       "8      22  \n",
       "9      22  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select final columns for output (NO sentiment)\n",
    "output_df = pairs_df[['character', 'emotion', 'context', 'response', 'dialogue_id', 'season', 'episode']].copy()\n",
    "\n",
    "# Save to CSV\n",
    "output_file = output_dir / \"meld_romantic_cleaned.csv\"\n",
    "output_df.to_csv(output_file, index=False)\n",
    "print(f\"Cleaned dataset saved to: {output_file}\")\n",
    "print(f\"Total rows: {len(output_df)}\")\n",
    "print(f\"\\nColumns in output file: {list(output_df.columns)}\")\n",
    "\n",
    "# Display final sample\n",
    "print(\"\\nFinal dataset sample:\")\n",
    "output_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook successfully processed MELD dataset for dating simulator training:\n",
    "\n",
    "1. **Loaded** YAML data with 3 splits (dev/test/train) - 13,707 total utterances\n",
    "2. **Parsed** nested structure into flat DataFrame\n",
    "3. **Sorted** chronologically by Season → Episode → StartTime\n",
    "4. **Filtered to romantic conversations**: Monica+Chandler, Ross+Rachel, Phoebe+dates, plus flirting scenes\n",
    "5. **Filtered to 1-on-1 only**: Removed all multi-party group conversations (3+ speakers)\n",
    "6. **Created** dialogue pairs with 5-utterance context windows WITH speaker tokens\n",
    "7. **Preserved** emotion labels and Friends character names\n",
    "8. **Saved** cleaned dataset ready for instruction fine-tuning\n",
    "\n",
    "**Output Format (for Dating Simulator):**\n",
    "- `character`: Friends character name (Chandler, Monica, Ross, Rachel, Joey, Phoebe)\n",
    "- `emotion`: Emotion label (anger, disgust, fear, joy, neutral, sadness, surprise)\n",
    "- `context`: Previous 5 utterances from same dialogue with speaker tokens in format `<Speaker> utterance`\n",
    "- `response`: Current utterance (target for generation)\n",
    "- `dialogue_id`, `season`, `episode`: Metadata for tracking\n",
    "\n",
    "**Why This Format Works for Dating Simulator:**\n",
    "\n",
    "1. **Romance context**: Only romantic/dating conversations, not platonic friend chats\n",
    "2. **1-on-1 format**: Matches dating simulator interaction (user + character)\n",
    "3. **Speaker tokens**: Included as `<Speaker>` to enable proper persona learning and turn attribution\n",
    "4. **Character personas**: Each Friends character has distinct personality for multi-persona training\n",
    "5. **Emotion conditioning**: Can train model to respond with specific emotions\n",
    "6. **NO sentiment**: Removed as not needed for dating simulator\n",
    "\n",
    "**Character Personas Available:**\n",
    "- **Chandler**: Sarcastic, witty, uses humor as defense, romantic underneath\n",
    "- **Monica**: Organized, competitive, nurturing, wants commitment\n",
    "- **Ross**: Intellectual, nerdy, overthinks, passionate but awkward\n",
    "- **Rachel**: Fashion-focused, fun, flirty, independent\n",
    "- **Joey**: Confident, simple, charming, food-focused\n",
    "- **Phoebe**: Quirky, spiritual, unconventional, direct\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "1. Create instruction formatting notebook to add:\n",
    "   - Persona definitions for each character\n",
    "   - Scenario descriptions\n",
    "   - LLaMA 3.1 instruction template format\n",
    "\n",
    "2. File: `notebooks/MELD/02_instruction_formatting__MELD.ipynb`\n",
    "\n",
    "3. Train with instruction fine-tuning:\n",
    "   ```bash\n",
    "   python src/training/train_dialogue.py \\\n",
    "       --data_path data/processed/MELD/meld_romantic_instruct.csv \\\n",
    "       --emotion_conditioned \\\n",
    "       --output_dir checkpoints/dating_sim_friends\n",
    "   ```\n",
    "\n",
    "4. Build dating simulator interface where user can:\n",
    "   - Select Friends character persona\n",
    "   - Set initial scenario\n",
    "   - Chat 1-on-1 with character\n",
    "\n",
    "**Dataset Size After Filtering:**\n",
    "Check the output statistics file for final counts after running this notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
